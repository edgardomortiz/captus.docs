[
  {
    "content": "This basic tutorial takes you through the minimal but most general workflow of the captus_assembly pipeline.\n0. Preparation Installation To run this tutorial, you need to install the following programs on your system:\nCaptus and its dependencies (see Installation) IQ-TREE version 2.0 or higher (see IQ-TREE documentation) If conda command is available, you can take the easiest way.\nSimply run the two commands below to set up and activate an environment:\nconda create -n captus -c bioconda -c conda-forge captus iqtree conda activate captus Check if Captus is installed:\ncaptus -h If a help message shows up in your terminal, you are ready to go!\nGetting data Download this file (169 MB) and place it in a directory where you want to run this tutorial.\nThen, run the following commands to unzip the archive.\ncd \u003cpath/to/your/directory\u003e # Replace with actual path tar -zxvf 00_raw_reads.tar.gz \u0026\u0026 rm 00_raw_reads.tar.gz Now you should have 00_raw_reads directory containing eight compressed FASTQ files: Those files are paired-end reads (R1 and R2) obtained from four plant species (GenusA_speciesA, GenusB_speciesB, GenusC_speciesC, GenusD_speciesD) by targeted-capture sequencing (CAP) of 353 loci highly conserved across angiosperms using the Angiosperms353 probe set (Johnson et al., 2018).\n1. Cleaning Reads Let’s start the analysis with cleaning the raw reads using the clean command.\nThe clean command trims adapter sequences and low-quality bases, and filters out reads with low average quality score. IMPORTANT When working with your own data, all FASTQ files must be named according to the naming convention.\nSince Captus automatically recognizes sample name and library layout (single-end or paired-end) from the FASTQ file name, improper file naming may cause improper data processing.\nRun the following command to perform a cleaning with default settings on all FASTQ files in the 00_raw_reads directory:\ncaptus clean -r 00_raw_reads -r : Path to directory containing FASTQ files. If you want to customize the cleaning criteria, see Options.\nThis command will creat 01_clean_reads directory with the following structure:\nOf these, the compressed FASTQ files (highlighted in the image above) are the cleaned reads and will be used in the next step.\nFor descriptions of the other output files, see Output Files and HTML Report.\n2. De Novo Assembly Next, we would like to assemble the clean reads into contigs using the assemble command.\nRun the following command to perform de novo assembly for all four samples with default settings optimized for targeted-capture and genome skimming data.\ncaptus assemble -r 01_clean_reads -r : Path to directory containing cleaned FASTQ files. You can tune the assembler settings for your own data, see Options.\nIf you are worried about contaminations, consider to use the --max_contig_gc option.\nThe command will create a directory, 02_assemblies with the following structure:\nOf these, assembly.fasta in each directory (highlighted in the image above) is the assembled contigs.\nFor descriptions of the other output files, see Output Files and HTML Report.\n3. Extracting Target Sequences Now is the time of judgement.\nWe would like to extract the target gene sequences from the contigs assembled in the previous step using the extract command.\nRun the following command to extract the sequences of all Angiosperms353 loci from all four samples:\ncaptus extract -a 02_assemblies -n Angiosperms353 -a : Path to the output directory from the assemble command. -n : Path to a FASTA file of reference sequences. Here we use the built-in Angiosperms353 reference dataset. Captus can extract multiple marker types (nuclear proteins, plastidial proteins, mitochondrial proteins, and miscellaneous DNA markers) simultaneously.\nFor plastidial and mitochondrial proteins, Captus offers built-in reference datasets, SeedPlantsPTD and SeedPlantsMIT. You can use them by simply adding -p SeedPlantsPTD and -m SeedPlantsMIT arguments to extract gene sequences from the organelle genomes of any flowering plants.\nFor descriptions of the other available options, see Options.\nIMPORTANT When providing your custom reference dataset, please make sure that all sequence names are formatted according to the Input Preparation.\nFor confirmation, Captus tells you in the log message how your reference dataset was recognized:\nNuclear proteins: reference: Angiosperms353 /path/to/reference/Angiosperms353.FAA reference info: 353 loci, 4,765 sequences (loci names found, detected multiple sequences per locus) The command will creat 03_extractions directory with the following structure:\nOf these, the FASTA files (*.faa and *.fna; highlighted in the image above) in each directory store the extracted sequences in each formats .\nFor descriptions of the other output files, see Output Files and HTML Report.\n4. Multiple Sequence Alignment The final step of the captus_assembly pipeline is to perform multiple sequence alignments on the sequences extracted from all samples for each locus using the align command to identify sequence variations among samples.\nRun the following command to align the sequences extracted in the previous step, as well as to trim gappy ends and filter out paralogs from the alignments:\ncaptus align -e 03_extractions -e : Path to the output directory from the extract command. For descriptions of the other available options, see Options.\nThe command will create 04_alignments directory with the following structure: Of these, 02_aligned_untrimmed and 03_aligned_trimmed directories (highlighted in the image above) store a series of untrimmed and trimmed alignments in multi-FASTA format, respectively.\nSince the structure of the output directory is a bit complicated, we recommend that you take a look at Output Files and HTML Report.\n5. Phylogenetic Inference One of the most typical analyses after the captus_assembly pipeline would be phylogenetic tree inference.\nHere we show a simple example of phylogenetic tree inference using IQ-TREE.\nRun the following commands to infer a concatenation-based species tree using all loci with an edge-linked partition model:\nmkdir 05_phylogeny \u0026\u0026 cd 05_phylogeny iqtree -p ../04_alignments/03_trimmed/06_informed/01_coding_NUC/02_NT -pre concat -T AUTO -p : NEXUS/RAxML partition file or path to a directory with alignments -pre : Prefix for output files -T : Number of cores/threads to use or AUTO-detect (default: 1) For more practical uses of IQ-TREE, see IQ-TREE documentation.\nThe command will create the following files: Of these, concat.treefile is the file storing the maximum-likelihood tree in Newick format.\nYou can visualize this tree with a phylogenetic tree viewer such as FigTree or Dendroscope.\nThe maximum-likelihood tree opened in FigTree and rerooted on GenusC_speciesC_CAP should look like below: That’s all for the basic tutorial, but remember that this is a minimal usage of the captus_assembly pipeline.\nTo get the most out of this pipeline, such as integrating different data types at different processing steps or discovering new markers by clustering contigs, check out the Advanced Tutorial (currently under construction).\nCreated by Gentaro Shigita (01.10.2021)\nLast modified by Gentaro Shigita (14.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Basic Tutorial",
    "uri": "/captus.docs/tutorials/assembly/basic/"
  },
  {
    "content": "Basics Discover the core-concepts behind Captus and how to get started.\n",
    "description": "",
    "tags": null,
    "title": "Basics",
    "uri": "/captus.docs/basics/"
  },
  {
    "content": "Under construction…\nHandling different data types Assembling reads cleaned outside Captus Combining all assembled data types Importing pre-assembled sample (e.g., GenBank ref genome) Extracting all marker types simultaneously Discovering new markers by clustering in capture data Adding new markers by clustering unused contigs (capture data) Phylogenetic tree reconstruction using palalogs - ASTRAL-Pro Created by Gentaro Shigita (01.10.2021)\nLast modified by Gentaro Shigita (31.10.2022)\n",
    "description": "",
    "tags": null,
    "title": "Advanced Tutorial",
    "uri": "/captus.docs/tutorials/assembly/advanced/"
  },
  {
    "content": "Captus’ first module is called captus_assembly but can also be executed as simply captus and it aims to create marker alignments across samples starting from the raw sequencing reads of each sample (or alternatively from previously cleaned reads or even previously assembled reads).\nTo accomplish this the module has four commands: clean, assemble, extract, and align which are tipically run in that order:\n1. clean This command will perform adaptor trimming (plus poly-A trimming if you are cleaning RNAseq reads) followed by quality trimming using bbduk.sh from the BBTools suite. Once the cleaning is completed, FastQC or Falco is run on the raw and cleaned reads and a HTML report is generated summarizing the results from all the samples.\n2. assemble Using the cleaned reads produced by the previous step, Captus will perform de novo assembly using MEGAHIT. The default assembly parameters are tuned for hybridization capture or genome skimming data or a combination of both (CAPSKIM preset), additionally we provide two more presets for RNA-Seq (RNA) or high-coverage Whole Genome Shotgun (WGS) data. MEGAHIT only outputs a rough estimation of depth of coverage for the assembled contigs, therefore we run Salmon right after assembly to rapidly and accurately estimate contig depth of coverage and automatically remove contigs with depth \u003c1.5x (but this default threshold can be changed). Captus can also remove contigs exceeding a given percentage of GC content. This is particularly useful if, for example, you are working with Eukaryotes and want to remove bacterial contamination, whose contigs typically have GC contents above 60 %. An HTML report summarizing several assembly statistics is also produced after this step. After examining the report, the filtering by GC content and/or minimum depth of coverage can be repeated multiple times without the need to reassemble the reads. Even though we recommend using the cleaned reads produced by the clean command you can also provide your own previously cleaned reads.\n3. extract During this step Captus will search the assemblies produced by the previous step for the loci contained in the provided reference target sequence datasetsets (aminoacids or nucleotides) and then extract them. Proteins can be provided in either aminoacid or nucleotide, these are searched and extracted using Scipio. Additionally, you can provide as reference targets any other DNA sequences (e.g., ribosomal genes, individual exons, entire genes with introns, non-coding regions, RAD loci, etc.), in this case Captus uses BLAT for searching and our own code for extracting and stitching partial hits if needed. Finally, since most of the contigs in the assembly are tipically not used because the targets will not be found in most contigs, we provide the option of clustering those unused contigs across samples using MMseqs2 in order to discover new putative homologous regions that can be used for phylogenomics. If you have your own assemblies in FASTA format you can use them instead of the assemblies produced by the assemble command (e.g., downloaded genomes from NCBI). Like in the previous steps, Captus will produce an HTML report summarizing the marker recovery statistics across all samples and extracted markers.\n4. align In this step Captus will process the results from the extract command. First, it will collect all the markers across samples and create a separate FASTA file per marker. Then, the reference sequences used for extraction will be added to their corresponding FASTA marker file to aid as an alignment guide. This is followed by alignment using MAFFT or MUSCLE. If you are aligning coding sequences, Captus will codon-align the nucleotide version using as template the aminoacid alignment of the locus. Captus extracts all the copies (hits) of a marker that are found in the assembly and ranks them by their similarity to the reference sequence, once the sequences are aligned, the program filters the paralogs using either the naive method which retains the best hit as the ortholog or the informed method which takes into account the references and the frequency with which they were selected across all samples to decide which of the copies most likely represents the ortholog (which is not necessarily the best hit). After paralogs have been filtered, the references used for guiding the alignment are removed. Finally, the alignments are trimmed using the recently published package ClipKIT. As in previous steps, Captus will summarize the alignment statistics of all the markers (e.g. length, mean pairwise identity, missingness, number of informative sites, etc.) and produce an HTML report.\nTo show the main help of the captus_assembly module just type captus --help:\n(captus)$ captus --help usage: captus command [options] Captus 1.1.0: Assembly of Phylogenomic Datasets from High-Throughput Sequencing data Captus-assembly commands: command Program commands (in typical order of execution) clean = Trim adaptors and quality filter reads with BBTools, run FastQC on the raw and cleaned reads assemble = Perform de novo assembly with MEGAHIT and estimate contig depth of coverage with Salmon: Assembling reads that were cleaned with the 'clean' command is recommended, but reads cleaned elsewhere are also allowed extract = Recover targeted markers with BLAT and Scipio: Extracting markers from the assembly obtained with the 'assemble' command is recommended, but any other assemblies in FASTA format are also allowed align = Align extracted markers across samples with MAFFT or MUSCLE: Marker alignment depends on the directory structure created by the 'extract' command. This step also performs paralog filtering and alignment trimming using ClipKIT Help: -h, --help Show this help message and exit --version Show Captus' version number For help on a particular command: captus_assembly command -h So, for example, if you want to show the help of the extract command you can type:\ncaptus extract --help Created by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (19.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Assembly",
    "uri": "/captus.docs/assembly/"
  },
  {
    "content": "Code is being refactored.\n",
    "description": "",
    "tags": null,
    "title": "Design",
    "uri": "/captus.docs/design/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tutorials",
    "uri": "/captus.docs/tutorials/"
  },
  {
    "content": " Basic Tutorial - The least things you should know Advanced Tutorial - Many more things you can do ",
    "description": "",
    "tags": null,
    "title": "Assembly",
    "uri": "/captus.docs/tutorials/assembly/"
  },
  {
    "content": "Unless you are starting with your own assemblies, cleaning will be the first step in the analysis. Captus makes it easy to process many samples in a consistent manner, automatically, and providing a comprehensive Quality Control HTML report.\nCaptus allows you the flexibility to provide reads cleaned elsewhere. however, we recommend our cleaning method for its accuracy in removing adaptors, which in turn improves the chances of getting a higher quality assembly.\nNote In case you still want to start with previously cleaned reads, you can jump ahead to the assemble command page.\nFurther reading: Why did we choose BBTools for data cleaning? We needed something FAST, but most importantly ACCURATE and RELIABLE. Years ago, Brian Bushnell, the author of BBTools, posted a comparison between his own bbduk.sh, and the popular Cutadapt and Trimmomatic. You can read the experiment setup and his results here.\nSince then, there have been new versions of these programs, and a new one, fastp, was published. Therefore, we updated the experiment including fastp, increasing the minimum length to 21 bp, and processing paired-end reads which is closer to the real use of these tools.\nAnother popular software, Trim Galore, was not considered because it is only a wrapper around Cutadapt, additionally, it displays some unusual behavior when used in Macs.\nFirst, we created a conda environment for the four selected programs:\nconda create -n rem_adaptors -c bioconda -c conda-forge bbmap cutadapt fastp trimmomatic conda activate rem_adaptors Then, we grabbed a million reads (PE 2x150 bp) from a plant genome project, reformat.sh is also part of BBTools:\nreformat.sh in=SB12_R#.fq.gz out=raw_R#.fq.gz reads=1000000 These are the same “rotated” (A-\u003eT, C-\u003eA, G-\u003eC, T-\u003eG) adaptors that were included in the file gruseq.fa that Bushnell made for his test:\n\u003eGruseq_Adapter_Index_1_6 CTGACCTTCTCATATACGAGCTTAGAATCGATATGATACTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_2 CTGACCTTCTCATATACGAGCTTAGAATCGATAACTGCGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_3 CTGACCTTCTCATATACGAGCTTAGAATCGATAGGTCCATGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_4 CTGACCTTCTCATATACGAGCTTAGAATCGATAGCTAATTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_5 CTGACCTTCTCATATACGAGCTTAGAATCGATATATCGCTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_6 CTGACCTTCTCATATACGAGCTTAGAATCGATACAATTGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_7 CTGACCTTCTCATATACGAGCTTAGAATCGATAATCTGATGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_8 CTGACCTTCTCATATACGAGCTTAGAATCGATATAGGCTTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_9 CTGACCTTCTCATATACGAGCTTAGAATCGATACTGATCTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_10 CTGACCTTCTCATATACGAGCTTAGAATCGATAGTCAGGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_11 CTGACCTTCTCATATACGAGCTTAGAATCGATACCAGTATGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_12 CTGACCTTCTCATATACGAGCTTAGAATCGATAAGGCGTTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_13 CTGACCTTCTCATATACGAGCTTAGAATCGATATCGATTATTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_14 CTGACCTTCTCATATACGAGCTTAGAATCGATATCGGAACGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_15 CTGACCTTCTCATATACGAGCTTAGAATCGATATGCGATCTTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_16 CTGACCTTCTCATATACGAGCTTAGAATCGATAAACGAAACTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_18_7 CTGACCTTCTCATATACGAGCTTAGAATCGATACGAACATATGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_19 CTGACCTTCTCATATACGAGCTTAGAATCGATACGCTTTACTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_20 CTGACCTTCTCATATACGAGCTTAGAATCGATACGCCAAGGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_21 CTGACCTTCTCATATACGAGCTTAGAATCGATACGGGACCTTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_22 CTGACCTTCTCATATACGAGCTTAGAATCGATAACGTACGTTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_23 CTGACCTTCTCATATACGAGCTTAGAATCGATACTCGCCTGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_25 CTGACCTTCTCATATACGAGCTTAGAATCGATATAGCTGTGTGAGACGTGCAACGAGGAGCAGGC \u003eGruseq_Adapter_Index_27 CTGACCTTCTCATATACGAGCTTAGAATCGATATGGAAGGGTGAGACGTGCAACGAGGAGCAGGC Now, we add those adaptors to the raw reads with another program from BBTools:\naddadapters.sh in=raw_R#.fq.gz out=dirty_R#.fq.gz qout=33 ref=gruseq.fa right addadapters.sh modifies the read headers adding the exact information of where was the adaptor inserted. For example, the adaptors were added from position 124 in this read:\n@4_150_124_150_124 /1 ANTAAAAAGAGTAGTGTCAGATAGCTTATATGGAGAAAGCCATAGCAATTTTATCAGTGCTGTAGAGGAATTAAAAATAGAATATGCAGTGGGAATCTGGAGCAATCATGGGGTCTGGCTTCCACTGACCTTCTCATATACGAGCTTAGA + F!FFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FF:F:FFFFFFFFFFF Now we proceed to remove these synthetic adaptors, these are the commands used for each software:\n# Cutadapt 3.4: time cutadapt -m 21 -j 0 -b \"file:gruseq.fa\" -B \"file:gruseq.fa\" -o cutadapt_R1.fq.gz -p cutadapt_R2.fq.gz dirty_R1.fq.gz dirty_R2.fq.gz # Trimmomatic 0.39: time trimmomatic PE -phred33 dirty_R1.fq.gz dirty_R2.fq.gz trimmomatic_R1.fq.gz trimmomatic_U1.fq.gz trimmomatic_R2.fq.gz trimmomatic_U2.fq.gz ILLUMINACLIP:gruseq.fa:2:28:10:2:keepBothReads MINLEN:21 # fastp 0.22.0: time fastp -w 8 -Q -l 21 --adapter_fasta gruseq.fa --detect_adapter_for_pe --in1 dirty_R1.fq.gz --in2 dirty_R2.fq.gz --out1 fastp_R1.fq.gz --out2 fastp_R2.fq.gz # bbduk.sh 38.92: time bbduk.sh in=dirty_R#.fq.gz out=bbduk_R#.fq.gz ref=gruseq.fa ktrim=r mink=12 hdist=1 minlen=21 tpe tbo # bbduk.sh 38.92 in Captus: time bbduk.sh ktrim=r minlength=21 interleaved=f tpe tbo ref=gruseq.fa in=dirty_R#.fq.gz out=stdout.fq k=21 mink=11 hdist=2 | bbduk.sh ktrim=r minlength=21 interleaved=f tpe tbo ref=gruseq.fa in=stdin.fq out=captus_R#.fq.gz k=19 mink=9 hdist=1 Finally, we use addapters.sh to grade the presence of adaptor of each set of reads:\naddadapters.sh in=dirty_R#.fq.gz grade addadapters.sh in=cutadapt_R#.fq.gz grade addadapters.sh in=trimmomatic_R#.fq.gz grade addadapters.sh in=fastp_R#.fq.gz grade addadapters.sh in=bbduk_R#.fq.gz grade addadapters.sh in=captus_R#.fq.gz grade The tests were made in a MacbookPro 2015 with 4 CPU cores (8 threads) and 16 GB of RAM, we can see in this table the summary of the times and the results from the grading of addadapters.sh:\nMetric dirty Cutadapt Trimmomatic fastp bbduk Captus Time to clean NA 3m42.848s 1m11.250s 1m42.455s 0m9.574s 0m15.249s Reads retained 100.000 93.345 92.514 92.997 93.002 92.994 Bases retained 100.000 74.53 74.436 73.970 74.268 74.186 Perfectly correct (Reads) 49.970 97.35 80.922 96.256 * 94.849 95.784 Perfectly correct (Bases) 49.970 96.92 86.426 96.035 * 93.900 95.099 Incorrect (Reads) 50.030 2.65 19.078 3.744 * 5.151 4.216 Incorrect (Bases) 50.030 3.08 13.574 3.965 * 6.100 4.901 Adaptors remaining (Reads) 50.030 2.41 5.846 1.830 * 3.866 2.798 Adaptors remaining (Bases) 25.182 0.28 0.422 0.049 * 0.193 0.105 Non-adaptor removed (Reads) 0.000 1.53 13.231 1.914 1.285 1.418 Non-adaptor removed (Bases) 0.000 0.04 0.218 0.566 0.308 0.325 All numbers (except times) represent percentages, Reads and Bases retained are shown as percentage of the input “dirty” reads, while all the rest are as percentage of each method’s number of reads and bases retained. Best values are in bold and italics and the second best only in bold.\nTrimmomatic is by far the least accurate in general, the rest have comparable high accuracies.\nThe most accurate method measured by most metrics [except Adaptors remaining (Bases) and Non-adaptor removed (Reads)] is Cutadapt, but at the cost of being the slowest. It is \u003e23x slower than bbduk.sh and \u003e14x slower than Captus’ settings for bbduk.sh.\nEven though fastp is slightly more accurate than bbduk.sh [as measured by all metrics, except Non-adaptor removed (Reads or Bases)], it takes \u003e10x longer to finish. More importantly, we put an * next to fastp’s winning values because when cleaning real unaltered data (without extra adapters added) we noticed that fastp sometimes mistakes real genomic sequence as adaptor, and we are not the only that noticed this, you can read about it in this GitHub Issue. In the future, if the developers of fastp fix the false detection problem we could incorporate it in the pipeline.\nThe fastest times correspond in both cases to bbduk.sh. Notably, the second most effective method in removing adaptor bases is bbduk.sh with Captus’s settings [see Adaptors remaining (Bases) after cleaning].\nOur preference for bbduk.sh is justified at this point by the balance between its high accuracy (\u003e95%) and its great speed (\u003e10x faster than the second fastest), but mainly because of its efficiency in removing adaptor bases from the reads.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (29.05.2022)\n",
    "description": "",
    "tags": null,
    "title": "Clean",
    "uri": "/captus.docs/assembly/clean/"
  },
  {
    "content": "Welcome to Captus, a toolkit for the assembly of phylogenomic datasets (many samples and loci) from High-Throughput Sequencing (a.k.a. Next Generation Sequencing) data. Captus was initially designed specifically for the assembly of target-enriched (e.g. via hybridization of RNA or DNA probes) sequencing data, but has since been expanded to accomodate other common types of HTS data such as Genome Skimming, Hyb-Seq (Target Enrichment + Genome Skimming), RNA-seq, and Whole Genome Sequencing. The toolkit will also include a module for the design of probes for target enrichment experiments.\nWe wanted to provide the same advantages that ipyrad provides for RAD-seq data. Following a similar “Ethos”, we wanted Captus to be:\nSimple: Easy to install and easy to use Fast: We optimized the speed of every step without sacrificing sensitivity Reproducible: Commands are clear, output directories are well organized, and extensive logs are always kept. Flexible: You can start the analysis with raw data or with your own cleaned or even assembled reads. You can add samples to your existing datasets without having to reanalyze everything or you can redo analysis on only a subset of samples. Transparent: We provide informative, well organized, and easy to read output as well as neat HTML reports so you can quickly assess the status of any sample at any stage of the workflow. ",
    "description": "",
    "tags": null,
    "title": "Overview",
    "uri": "/captus.docs/basics/overview/"
  },
  {
    "content": "If you cleaned your reads using Captus then the data is ready for analysis inside the directory you chose for the cleaned reads (./01_cleaned_reads/ by default). Then you can proceed to check the Options of the assemble command.\nNote If you want to provide reads cleaned elsewhere, please follow the same naming convention required for raw reads and place your FASTQ files preferably in a single directory.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (29.05.2021)\n",
    "description": "",
    "tags": null,
    "title": "Input Preparation",
    "uri": "/captus.docs/assembly/assemble/preparation/"
  },
  {
    "content": " Note Before starting your analysis, a VERY IMPORTANT step is to rename your FASTQ files so they clearly identify your samples throughout the entire analysis.\nIn general, a good tip for renaming your samples is to think on how you want the names in your final phylogenetic tree.\nThe only special characters that are safe to use in the sample name are -, and _ (_ is commonly used to replace spaces in many phylogenetic programs). Otherwise, do not use spaces, other special characters (! \" # $ % \u0026 ( ) * + , . / : ; \u003c = \u003e ? @ [ \\ ] ^ ` { | } ~), or accented letters (like á, è, ü, ç, ñ), they are just guaranteed to give you headaches at some point.\nAlso, please use this naming convention for your FASTQ files:\nIMPORTANT: Even though underscores (_) are allowed in sample names, please DO NOT use more than ONE consecutive _ in any case. We use double underscores (__) internally to separate several pieces of information during the processing and for the output (see for example the FASTA headers of extracted markers). Any text found before the _R# pattern and the extension will become your sample name (Pouteria_lucuma_EO9854 in this case). If you are using paired-end reads, your R1 and R2 filenames should contain the patterns _R1 and _R2 respectively to be correctly matched and used as pairs. For single-end your filenames should still contain _R1. These are the valid extensions: .fq, .fastq, .fq.gz, and .fastq.gz. These are examples of valid FASTQ filenames for Captus:\nArabidopsis_thaliana_R1.fq.gz and Arabidopsis_thaliana_R2.fq.gz, these will be correctly taken as a pair Mus_musculus_GX763763_R1.fastq, if its corresponding R2 is not found it will be used as single-end ERI_Demosthenesia_mandonii_EO2765_R1.fastq.gz and ERI_Demosthenesia_mandonii_EO2765_R2.fastq.gz A_R1.fq and A_R2.fq And here, some examples or invalid FASTQ filenames:\nERR246535_1.fastq.gz and ERR246535_2.fastq.gz, notice they lack the _R1 and _R2 patterns in the names, Captus is not able to match these as a pair Octomeles_sp.1_R1.fastq, it is better to replace the . in the sample name by a - to get Octomeles_sp-1_R1.fastq Malus_doméstica.fast, the sample name contains and accent é, but most importantly, it will be ignored because of the invalid extension .fast Created by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (30.05.2022)\n",
    "description": "",
    "tags": null,
    "title": "Input Preparation",
    "uri": "/captus.docs/assembly/clean/preparation/"
  },
  {
    "content": "At this point you should have de novo assemblies from your samples ready. However, Captus also gives you the flexibility of starting the analysis from this point by providing your own assemblies as FASTA files or complementing you newly aasembled samples with other assemblies (e.g. genomes or transcriptomes from GenBank). If you want to do so, please read the following note:\nHow to rename your FASTA assemblies for Captus Note In order to add your own FASTA assembly files, a VERY IMPORTANT step is to rename them so they are clearly identified throughout the rest of the analysis.\nIn general, a good tip for renaming your samples is to think on how you want the names in your final phylogenetic tree.\nThe only special characters that are safe to use in the sample name are -, and _ (_ is commonly used to replace spaces in many phylogenetic programs). Otherwise, do not use spaces other special characters (! \" # $ % \u0026 ( ) * + , . / : ; \u003c = \u003e ? @ [ \\ ] ^ ` { | } ~) or accented letters (like á, è, ü, ç, ñ), they are just guaranteed to give you headaches at some point.\nAlso, please use this naming convention for your FASTA files:\nIMPORTANT: Even though _ is allowed for sample names, please DO NOT use more than ONE consecutive _ in any case. We use internally __ to separate several pieces of information during the processing. Any text before the extension will become your sample name (Mus_musculus_GRCm39 in this case). Valid extension for assemblies are: .fa, .fna, .fasta, .fa.gz, .fna.gz, .fasta.gz. These are examples of valid FASTA filenames for marker extraction with Captus:\nArabidopsis_arenosa.fna.gz Mus_cervicolor_GY747683.fasta ERI_Vaccinium_macrocarpon.fa.gz Z.fa And here, some examples or invalid FASTA filenames:\nERR246535.fast will be ignored because of the invalid extension .fast Octomeles_sp.8.fasta, it is better to replace the . in the sample name by a - to get Octomeles_sp-8.fasta Malus_spontánea.fna.gz, the sample name contains and accent á, it is better to change it to Malus_spontanea.fna.gz Reference target datasets formatting Most importantly, in order to extract markers, the sequences in your reference target datasets have to follow a simple naming convention if you want to take advantage of using multiple reference sequences per locus and our paralog filtering method. When multiple reference sequences per locus are found in the reference dataset, Captus will decide during the extraction which of those references matches your assembly best based on similarity and total recovered length percentage.\nHere is an example of a reference protein dataset that has two loci (called accD and cemA) with five reference sequences each (probably coming from different taxa to expand phylogenetic coverage). Coding sequences can be provided in either aminoacid or nucleotide. Miscellaneous DNA markers references can only contain nucleotide sequences.\n\u003eAA-S46062.1-accD [cluster_size=80] MALQSLRGSMRSVVGKRICPLIEYAIFPPLPRIIVYASRRARMQRGNYSLIKKPKKVSTLRQYQSTKSPMYQSLQRICGVREWLNKYCMWKEVDEKDFG* \u003eAAZ94660.1-accD [cluster_size=17] MEKRWLNSMLSKGELEYRCRLSKSINSLGPIESEGSIINNMNKNIPSHSDSYNSSYSTVDDLVGIRNFVSYDTFLVRDSNSSSYSIYLDIENQIFEIDN* \u003eABH88096.1-accD [cluster_size=3] MQKWRFNSMLLNRELEYGCEFKESLGPIENTSLNEEPKILSDIHKKINRWDDSDNSSYNSLDYLVGADNIQDFLSDKTFLVRDNKRNSYSIYLDIEKKT* \u003eABW20568.1-accD [cluster_size=7] MQNWINNSFQAEFEQESYFGSLGENSMNPRSGGDRYPEALIIRDITGETSAIYFDITDQILENDTHQTILASPIENDLWAEKDISIDIYRYINELIFYD* \u003eACU46588.1-accD [cluster_size=1] MAKYWFNLMLSYKMLSYNKLEHRCGLSKSMDNLNDLGHIGGNEELILNENDAKKNILGLENYNTHSINYLFDSRNIYNLIYNETFLVRNSNGYHYFVYF* \u003eQNK04966.1-cemA [cluster_size=1] MKNKKAFIPLLHITFIVFLPWWIAFLFNKGLESWVINWWNTSKSEIFLNDIQEKNILEKFIELEELLLLDEMIKEYPET* \u003eQNP0849-5.1-cemA [cluster_size=4] MTKKKAFTPIFYLSFLLFLPWWIDLLFNKCLRSWPTHWWNTRQSEMFLTTLQEKSLLEKFLELEEFLFLDKIIKKEFET* \u003eQNP08626.1-cemA [cluster_size=2] MIKNKVFTPLFYLAFIVFLPWGIYFLLNKCMGSWTTNWWTTRESEILSTNINENSLLEKFIQFEEFLLLDEIIKKDTET* \u003eQNQ64689.1-cemA [cluster_size=9] MAKNKICIPFISIVFLPWWISFLFKKDFESWVTNWWNTSKSEILLNDIQEKSILKTFIELEELFLLDEMLKEYPETRLQ* \u003eQPZ48083.1-cemA [cluster_size=7] MAKKKAFISLIYLASIVFLPWWLSFTFNKSMESWVKNCWNTGPSENFLNDIEEKIIIKKFIELEELSLFDEILKDYTQD* Let’s take a look at how the sequence names are formatted:\nThe sequence name (any text found before the first space) can contain multiple - characters, but only the last one will become the separator. Any text found before the separator will be considered as sequence ID. Any text found after the the separator will become the locus name. Any text found after the first space is considered the description and this text is optional. Angiosperms353 and HybPiper use this format, therefore, in order to mantain compatibility, we also used it to build our reference datasets for plastome proteins SeedPlantsPTD and mitochondrial proteins SeedPlantsMIT. At the same time it is also compatible with the references needed by other pipelines (e.g. SeCaPr) which are only capable of dealing with a single sequence per locus.\nWarning When the separator is not present (even in a single sequence in the whole reference dataset), the entire sequence name will be used as the locus name. This is fine when your reference dataset only contains a single sequence per locus for example, but if you intend to use the “muti-sequence per locus” format, please ensure that every single sequence contains a - as separator.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (29.05.2021)\n",
    "description": "",
    "tags": null,
    "title": "Input Preparation",
    "uri": "/captus.docs/assembly/extract/preparation/"
  },
  {
    "content": "align To show all available options and their default values you can type in your terminal:\ncaptus align --help Input -e, --captus_extractions_dir Path to the output directory from the extract command, (e.g. 03_extractions iy you used the default name). The align command depends entirely on the output from the extract step, in other words, you can’t provide your unaligned or aligned FASTA files for processing.\nThis argument is required , the default is ./03_extractions/\n-m, --markers Which type(s) of markers to align, you can provide a comma-separated list (no spaces). These are the available marker types:\nNUC = Nuclear proteins inside directories ‘01_coding_NUC’ PTD = Plastidial proteins inside directories ‘02_coding_PTD’ MIT = Mitochondrial proteins inside directories ‘03_coding_MIT’ DNA = Miscellaneous DNA markers inside directories ‘04_misc_DNA’ CLR = Cluster-derived DNA markers inside directories ‘05_clusters’ ALL = Shortcut for NUC,PTD,MIT,DNA,CLR This argument is optional, the default is ALL.\n-f, --formats For each marker type, Captus creates several different formats. You can provide a comma-separated list (no spaces) of the formats you wish to align. These are the available formats:\nAA = Coding sequences in aminoacids NT = Coding sequences in nucleotides GE = Complete gene sequences (exons + introns) without extra flanking sequence GF = Complete gene sequences with flanking upstream and downstream basepairs MA = Matched sequences without extra flanking sequence MF = Matched sequences with flanking upstream and downstream basepairs ALL = Shortcut for AA,NT,GE,GF,MA,MF * AA, NT, GE, and GF are valid only for NUC, PTD, and MIT markers, while MA and MF are valid only for DNA and CLR\nThis argument is optional, the default is AA,NT,GE,MA\nFormats for protein markers Formats for miscellaneous DNA markers --max_paralogs Maximum number of secondary hits (copies) per sample to import from the extraction step. Large numbers of marker copies per sample can increase alignment times. Hits (copies) are ranked from best to worst during the ’extract’ step. -1 disables the initial removal of paralogs and aligns which might be useful if you expect very high ploidy levels for example.\nThis argument is optional, the default is 5\n--min_samples Minimum number of samples in a marker to proceed with alignment. Markers with fewer samples will be skipped. The default 4 corresponds to smallest number of sequences to build a rooted phylogeny.\nThis argument is optional, the default is 4\nOutput -o, --out With this option you can redirect the output directory to a path of your choice, that path will be created if it doesn’t already exist.\nThis argument is optional, the default is ./04_alignments/\n--keep_all Many intermediate log files are created by MAFFT/MUSCLE and ClipKIT during assembly, Captus deletes all the unnecesary intermediate files unless you enable this flag.\n--overwrite Use this flag with caution, this will replace any previous result within the output directory (for the sample names that match).\nAlignment --align_method Select the alignment algorithm for MAFFT or MUSCLE 5. Valid algorithm names are:\nmafft_auto = MAFFT’s automatic selection based on amount of data mafft_genafpair = MAFFT’s E-INS-i (very slow, multiple conserved domains and long gaps) mafft_localpair = MAFFT’s L-INS-i (very slow, one conserved domain and long gaps) mafft_globalpair = MAFFT’s G-INS-i (very slow, global homology) mafft_retree1 = MAFFT’s FFT-NS-1 (fast, progressive method) mafft_retree2 = MAFFT’s FFT-NS-2 (very fast, progressive method) muscle_align = MUSCLE 5’s default PPP algorithm (very slow) muscle_super5 = MUSCLE 5’s Super 5 algorithm (slow) This argument is optional, the default is mafft_auto.\n--timeout Modify the waiting time in seconds for an individual alignment to complete. When using more exhaustive MAFFT algorithm (e.g., genafpair) or especially MUSCLE (considerably slower than MAFFT in general), alignment can take very long (up to hours depending on sample number an length of the sequences).\nThis argument is optional, the default is 21600 (= 6 hours).\n--disable_codon_align When AAs and their corresponding NTs are aligned in the same run, Captus uses the AA alignment as template for aligning the NT format, thus obtaining a codon-aware alignment for the coding sequences in nucleotides. Use this flag to disable this method and use the regular MAFFT/MUSCLE nucleotide alignment.\n--outgroup Outgroup sample names, separated by commas, no spaces. Captus will place these samples whenever possible at the beginning of the alignments, since many phylogenetic programs root the resulting phylogeny at the first sample in the alignment your trees will be automatically rooted.\nExample: --outgroup sample2,sample5\nThis argument is optional and has no default.\nParalog filtering --filter_method We provide two filtering methods for paralog removal, you can select either or both:\nnaive = Only the best hit for each sample (marked as hit=00) is retained. informed = Only keep the copy (regardless of hit ranking) that is most similar to the reference sequence that was chosen most frequently among all other samples in the alignment. This method was designed to take advantage of references that contain several sequences per locus (like Angiosperms353), if the reference only contains a single reference per locus the result will be very similar to the naive method (see --tolerance). both = Two separate folders will be created, each containing the results from each filtering method. none = Skip paralog removal, just remove reference sequences from the alignments. Useful for phylogenetic methods that allow paralogs like ASTRAL-Pro. This argument is optional, the default is both.\n--tolerance Only applicable to the informed filter. If the selected copy’s identity to the most commonly chosen reference is below this number of Standard Deviations from the mean, it will also be removed (the lower the number the stricter the filter).\nThis argument is optional, the default is 2.0.\nTrimming (ClipKIT) --clipkit_method Select ClipKIT’s trimming mode. Valid trimming modes are:\nsmart-gap gappy kpic kpic-smart-gap kpic-gappy kpi kpi-smart-gap kpi-gappy This argument is optional, the default is gappy.\n--clipkit_gaps Gappyness threshold per position. Accepted values between 0 and 1. This argument is ignored when using the kpi and kpic algorithms or intermediate steps that use smart-gap.\nThis argument is optional, the default is 0.9.\n--min_data_per_column Minimum number of non-missing sites per column. When this parameter is \u003e 0, Captus will dynamically calculate a --clipkit_gaps threshold per alignment to keep this minimum amount of data per column.\nThis argument is optional, the default is 0.\n--min_coverage Minimum coverage of sequence as proportion of the mean of sequence lengths in the alignment, ignoring gaps. After ClipKIT finishes trimming columns, Captus will also remove short sequences below this threshold.\nThis argument is optional, the default is 0.4.\nOther --collect_only Only collect the markers from the extraction folder and exit, it skips the addition of reference target sequences and subsequent steps\n--redo_from You can repeat the analysis without undoing all the steps. These are the points from which you can restart the align command:\nalignment = Delete all subdirectories with alignments and restart. filtering = Delete all subdirectories with paralog-filtered alignments and restart. removal = Delete all subdirectories with alignments whose references have been removed and restart. trimming = Delete all subdirectories with trimmed alignments and restart. This argument is optional and has no default.\n--mafft_path, --muscle_path, --clipkit_path If you have installed your own copies of MAFFT, MUSCLE or ClipKIT you can provide the full path to those copies.\nThese arguments are optional, the defaults are mafft and clipkit respectively.\n--show_less Enable this flag to show individual alignment information during the run. Detailed information is written regardless to the log.\n--ram, --threads, --concurrent, --debug, See Parallelization (and other common options)\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (18.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Options",
    "uri": "/captus.docs/assembly/align/options/"
  },
  {
    "content": "assemble To show all available options and their default values you can type in your terminal:\ncaptus assemble --help Input -r, --reads With this option you provide the location of your clean FASTQ files, there are several ways to list them:\nDirectory: providing the path to the directory containing your cleaned FASTQ files is the typical way to tell Captus which files to analyze. Subdirectories will not be searched in this case. If you cleaned your reads with Captus just use -r 01_clean_reads or the name you gave to the output directory.\nList of files: you can also provide the individual path to each of your FASTQ files separated by a single space. This is useful if you only want to analyze only a couple of samples within a directory with many other samples. Another use for lists is when your FASTQ files are located in different directories.\nUNIX pattern: another easy way to provide lists of files is using the wildcards * and ? to match many or just one character respectively.\nThis argument is required , the default is ./01_clean_reads/\nRead this if you want to assemble FASTQ files cleaned elsewhere Imagine that you have a directory clean_reads with the following structure:\nclean_reads ├── A_R1.fastq.gz ├── A_R2.fastq.gz ├── B_R1.fastq.gz ├── B_R2.fastq.gz ├── C_R1.fq ├── C_R2.fq ├── D_R1.fq └── D_R2.fq If you want to analyze all the FASTQ files in clean_reads you can simply use -r clean_reads To analyze only samples A and D: -r cleaned_reads/A_R1.fastq.gz cleaned_reads/A_R2.fastq.gz cleaned_reads/D_R1.fq cleaned_reads/D_R2.fq or more easily -r cleaned_reads/A_R?.fastq.gz cleaned_reads/D_R?.fq --sample_reads_target In case that you want to subsample a fixed amount of reads (e.g. if your FASTQ files have hundreds of millions of reads) you can indicate the number with this option. For example, --sample_reads_target 10_000_000 will randomly sample 10 million reads (if single-end) or 10 million pairs (if paired-end).\nThis argument is optional, the default is 0 (no subsampling).\nOutput -o, --out With this option you can redirect the output directory to a path of your choice, that path will be created if it doesn’t already exist. Inside this directory, the assembly of each sample will be stored in a subdirectory with the ending __captus-asm.\nThis argument is optional, the default is ./02_assemblies/\n--keep_all Many intermediate files are created by MEGAHIT during assembly, some are large (like the individual FASTA files from each kmer size), Captus deletes all the unnecesary intermediate files unless you enable this flag.\n--overwrite Use this flag with caution, this will replace any previous result within the output directory (for the sample names that match).\nde novo Assembly (MEGAHIT) --k_list Comma-separated list (no spaces) of kmer sizes, all must be odd values in the range 15-255, in increments of at most 28. The final kmer size will be adjusted automatically so it never exceeds the mean read length of the sample by more than 31 (so don’t worry if the largest kmer size in the default list seems too big for your read length).\nThis argument is optional, default is --k_list in the default --preset.\n--min_count Minimum contig depth (called multiplicity in MEGAHIT). Acceptable values are integers \u003e= 1. If your FASTQ files have many tens of million reads, it is recommended to use --min_count 3 or higher to avoid low-coverage contigs resulting from erroneous reads (the higher the sequencing depth, the higher the number of reads with errors that will get assembled into spurious contigs).\nThis argument is optional, defaults is --min_count in the default --preset.\n--prune_level Prunning strength for low-coverage edges during graph cleaning. Increasing the value beyond 2 can speed up the assembly at the cost of losing low-depth contigs. Acceptable values are integers between 0 and 3.\nThis argument is optional, defaults is --prune_level in the default --preset.\n--merge_level Thresholds for merging complex bubbles, the first number multiplied by the kmer size represents the maximum bubble length to merge, the second number represents the minimum similarity required to merge bubbles. For example, --merge_level 20,0.97 at kmer 175 will merge any two paths of at least 175 bp x 20 (3500 bp) with a similarity \u003e= 97%.\nThis argument is optional, the default is 20,0.95.\n--preset The default preset ‘CAPSKIM’ has optimized settings that work well with either hybridization capture or genome skimming data (or a combination of both). We have also optimized other MEGAHIT parameter combinations specific to high-coverage (\u003e= 30x depth) WGS data or RNA-Seq data. These modes will only work well with at least 8 GB of RAM. If, in addition to a preset, you provide your own k_list, min_count, or prune_level, your settings take priority over the preset’s.\nCAPSKIM = --k-list 31,39,47,63,79,95,111,127,143,159,175 --min-count 2 --prune-level 2 RNA = --k-list 27,47,67,87,107,127,147,167 --min-count 2 --prune-level 2 WGS = --k-list 31,39,49,69,89,109,129,149,169 --min-count 3 --prune-level 2 --no-mercy This argument is optional, the default is CAPSKIM.\n--min_contig_len Minimum contig length in bp in output assembly.\nThis argument is optional, the default is auto (= mean read length + smallest kmer in k_list).\n--tmp_dir MEGAHIT needs a temporary directory in an internal hard drive, otherwise it refuses to run.\nThis argument is optional, the default is $HOME.\n--max_contig_gc Maximum GC percentage allowed per contig. Useful to filter contamination. For example, bacteria usually exceed 60% GC content while eukaryotes rarely exceed that limit. 100.0 disables the GC filter.\nThis argument is optional, the default is 100.0 (filter disabled).\n--disable_mapping Disable mapping the reads back to the contigs using Salmon for accurate depth estimation. If disabled, the approximate depth estimation given by MEGAHIT will be used instead.\n--min_contig_depth Minimum contig depth of coverage in output assembly; ‘auto’ will retain contigs with depth of coverage greater than 1.0x when ‘–disable_mapping’ is chosen, otherwise it will retain only contigs of at least 1.5x. Accepted values are decimals greater or equal to 0. Use 0 to disable the filter.\nThis argument is optional, the default is auto (\u003e=1.5x, or \u003e1.0x when using --disable_mapping).\n--redo_filtering Enable if you want to try different values for --max_contig_gc or --min_contig_depth. Only the filtering step will be repeated.\nOther --reformat_path, --megahit_path, --megahit_toolkit_path, --salmon_path If you have installed your own copies of reformat.sh (from BBTools) or MEGAHIT (and its megahit_toolkit) or Salmon you can provide the full path to those copies.\nThese arguments are optional, the defaults are reformat.sh, megahit, megahit_toolkit, and salmon respectively.\n--ram, --threads, --concurrent, --debug, --show_less See Parallelization (and other common options)\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (18.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Options",
    "uri": "/captus.docs/assembly/assemble/options/"
  },
  {
    "content": "clean To show all available options and their default values you can type in your terminal:\ncaptus clean --help Input -r, --reads With this option you provide the location of your raw FASTQ files, there are several ways to list them:\nDirectory: the path to the directory containing your FASTQ files is usually the easiest way to tell Captus which files to analyze. When you provide a directory, Captus searches within all its subdirectories for files with valid FASTQ extensions.\nList of files: you can also provide the individual path to each of your FASTQ files separated by spaces. This is useful if you only want to analyze only a couple of samples within a directory with many other samples for example. Another use for lists is when your FASTQ files are located in different directories.\nUNIX pattern: another easy way to provide lists of files is using the wildcards * and ? to match many or just one character respectively.\nThis argument is required .\nExamples Imagine that your directory raw_reads has the following structure:\nraw_reads ├── batch_1 │ ├── C_R1.fastq │ ├── C_R2.fastq │ ├── D_R1.fastq │ └── D_R2.fastq ├── A_R1.fq.gz ├── A_R2.fq.gz ├── B_R1.fq.gz └── B_R2.fq.gz If you want to analyze all the FASTQ files in raw_reads (including the subdirectory batch_1) you can simply use -r raw_reads To analyze only samples A and D: -r raw_reads/A_R1.fq.gz raw_reads/A_R2.fq.gz raw_reads/batch_1/D_R1.fastq raw_reads/batch_1/D_R2.fastq or more easily -r raw_reads/A_R?.fq.gz raw_reads/batch_1/D_R?.fastq To analyze only the samples inside raw_reads but not in batch_1: -r raw_reads/*.* Output -o, --out With this option you can redirect the output directory to a path of your choice, that path will be created if it doesn’t already exist.\nThis argument is optional, the default is ./01_clean_reads/\n--keep_all Many intermediate files are created during the read cleanup, some are large (like FASTQ files) while others small (like temporary logs). Captus deletes all the unnecesary intermediate files unless you enable this flag.\n--overwrite Use this flag with caution, this will replace any previous result within the output directory (for the sample names that match).\nAdaptor trimming --adaptor_set We have bundled with Captus adaptor sequences, these options are available:\nIllumina = Adaptor set copied from BBTools. BGI = Including BGISEQ, DNBSEQ, and MGISEQ. ALL = If you are unsure of the technology used for your sequences this combines both sets of adaptors. This argument is optional, the default is ALL.\n--rna Enable this flag to trim poly-A tails from RNA-Seq reads.\nQuality trimming and filtering Here you can control PHRED quality score thresholds. BBTools uses the PHRED algorithm to trim low-quality bases or to discard low-quality reads.\n--trimq Leading and trailing read regions with average PHRED quality score below this value will be trimmed.\nMany people raise this value to 20 or even higher but that usually discards lots of useful data for de novo assembly. In general, unless you have really high sequencing depth, don’t increase this threshold beyond ~16.\nThis argument is optional, the default is 13.\n--maq Once the trimming of low-quality bases from both ends of the reads has been completed, the average PHRED score of the entire read is recalculated and reads that do not have at least this minimum average quality are discarded.\nAgain, very high thresholds will throw away useful data. In general, set it to at least trimq or just a couple numbers higher.\nThis argument is optional, the default is 16.\n--ftl Trim any base to the left of this position. For example, if you want to remove 4 bases from the left of the reads set this number to 5.\nThis argument is optional, the default is 0 (no ftl applied).\n--ftr Trim any base to the right of this position. For example, if you want to truncate your reads length to 100 bp set this number to 100\nThis argument is optional, the default is 0 (no ftr applied).\nQC Statistics --qc_program Select the program for obtaining the statistics from your FASTQ files. Both programs should return identical results, but Falco is much faster. Valid options are:\nFalco FastQC This argument is optional, the default is FastQC.\n--skip_qc_stats This flag disables the Falco or FastQC analysis, keep in mind that the final HTML report can’t be created without the results from this analysis.\nOther --bbduk_path, --falco_path, --fastqc_path If you have installed your own copies of bbduk.sh, Falco, or FastQC you can provide the full path to those copies.\nThese arguments are optional, the defaults are bbduk.sh, falco, and fastqc respectively.\n--ram, --threads, --concurrent, --debug, --show_less See Parallelization (and other common options)\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (18.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Options",
    "uri": "/captus.docs/assembly/clean/options/"
  },
  {
    "content": "extract To show all available options and their default values you can type in your terminal:\ncaptus extract --help Input -a, --captus_assemblies_dir Path to the output directory from the assemble command, (e.g. 02_assemblies if you used the default name). If you didn’t assemble any sample in Captus this directory will be created in order to import your contigs assembled elsewhere.\nThis argument is required , the default is ./02_assemblies/\n-f, --fastas With this option you can provide the location of your own FASTA assembly files, there are several ways to list them:\nDirectory: the path to the directory containing your FASTA files assembled elsewhere. This will be the typical way to tell Captus which assemblies to import prior to marker extraction. All subdirectories will be searched for FASTA (.fa, .fna, .fasta, .fa.gz, .fna.gz, .fasta.gz) files in this case.\nList of files: you can also provide the individual path to each of your FASTA file separated by a single space. This is useful if you only want to analyze only a couple of samples within a directory with many other samples. Another use for lists is when your FASTA assembly files are located in different directories.\nUNIX pattern: another easy way to provide lists of files is using the wildcards * and ? to match many or just one character respectively.\nRemember, all the FASTA files provided with this option will be imported to the path set by --captus_assemblies_dir\nThis argument is optional and has no default.\nOutput -o, --out With this option you can redirect the output directory to a path of your choice, that path will be created if it doesn’t already exist.\nInside this directory, the extracted markers for each sample will be stored in a subdirectory with the ending __captus-ext.\nThis argument is optinal, the default is ./03_extractions/\n--ignore_depth Do not filter contigs based on their depth of coverage (default behavior before version 1.1.0).\n--disable_stitching Use this flag only if you are sure your target loci will be found in a single contig (for example if you have a chromosome-level assembly). By default, Captus tries to join partial matches to a target that are scattered across multiple contigs if their structure and overlaps are compatible. Internally, this activates the --single_target_hits option for Scipio when searching for proteins.\n--max_paralogs Maximum number of secondary hits (copies) of any particular reference marker allowed in the output. We recommend disabling the removal of paralogs (secondary hits/copies) during the extract step because the align step uses a more sophisticated filter for paralogs. This can be useful for exploratory runs, for example: if after an initial run allowing all paralogs we found out that the average number of secondary hits across samples is 5, we could use this number to get rid of outliers.\nThis argument is optional, the default is -1 (include all paralogs in the output).\n--max_loci_files When the number of loci in the reference exceeds this value, Captus will not write a separate FASTA file per sample per marker, otherwise the hard drive fills up with tons of small files. The file that includes all the extracted markers grouped per sample is still written (this is the only file needed by the final step align to produce the marker alignments across all samples).\nThis argument is optional, the default is 0 (do not write separate loci files).\n--keep_all Many intermediate files are created during the marker extraction, some are large (like BLAT’s .psl files) while others small temporary logs of intermediate steps, Captus deletes all the unnecesary intermediate files unless you enable this flag.\n--overwrite Use this flag with caution, this will replace any previous result within the output directory (for the sample names that match).\nProteins extraction global options (Scipio) --max_loci_scipio_x2 When the number of loci in a protein reference file exceeds this number, Captus will not run a second, more exhaustive round of Scipio. Usually the results from the first round are extremely similar and sufficient, the second round can become extremely slow as the number of reference proteins grows.\nThis argument is optional, the default is 2000.\n--predict Scipio flags introns as dubious when the splice signals are not found at the exon edges, this may indicate that there are additional aminoacids in the recovered protein that are not present in the reference protein. Enable this flag to attempt translation of these dubious introns, if the translation does not introduce premature stop codons they will be added to the recovered protein. Recommended if you are extracting from RNA assemblies (introns would have been removed in this type of data).\nNuclear proteins (Scipio) -n, --nuc_refs The reference set of nuclear proteins to search and extract from the assemblies. Captus includes two sets:\nAngiosperms353 = extract the original Angiosperms353. Mega353 = extract the later expanded version of Angiosperms353; because Mega353 includes many more sequences, processing times become longer. Alternatively, you can provide the path to a FASTA file (e.g. -n my_refs/my_nuclear_prots.fa) that includes your own coding references either in nucleotide or aminoacid. If you provide a nucleotide file, please also specify the translation table to be used, otherwise Captus will translate it using --nuc_transtable 1, the “Standard code”. See the complete list of translation tables.\nThis argument is optional and has no default.\n--nuc_transtable If you provide a nucleotide file for extraction you can specify the genetic code to translate it.\nThis argument is optional, the default is 1 (= the “Standard code”. See the complete list of translation tables).\n--nuc_min_score Keep hits to the reference proteins that have at least this Scipio score. The default has been optimized to perform cross-species extraction in fragmented assemblies like the ones obtained from hybridization capture data. Accepted values are decimals from 0 to 1. For more details, read Scipio’s settings.\nThis argument is optional, the default is 0.13.\n--nuc_min_identity Minimum percentage of identity to the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 65.\n--nuc_min_coverage Minimum percentage of coverage of the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 20.\n--nuc_depth_tolerance Allow nuclear contigs with a minimum depth equal to the median depth divided by this number and a maximum depth equal to the median depth multipled by this number. This median depth is calculated only from the contigs with hits to the nuclear proteins.\nThis argument is optional, the default is 20.\nPlastidial proteins (Scipio) -p, --ptd_refs The reference set of plastidial proteins to search and extract from the assemblies. The options available are:\nSeedPlantsPTD = Set of chloroplast proteins that spans all Seed Plants (curated by us). Alternatively, you can provide the path to a FASTA file (e.g. -p my_refs/my_plastome_prots.fa) that includes your own coding references either in nucleotide or aminoacid. If you provide a nucleotide file, please also specify the translation table to be used, otherwise Captus will translate it using --ptd_transtable 11, the “Bacterial, Archaeal and Plant Plastid code”. See the complete list of translation tables.\nThis argument is optional and has no default.\n--ptd_transtable If you provide a nucleotide file for extraction you can specify the genetic code to translate it.\nThis argument is optional, the default is 11 (= the “Bacterial, Archaeal and Plant Plastid code”. See the complete list of translation tables).\n--ptd_min_score Keep hits to the reference proteins that have at least this Scipio score. The default has been optimized to perform cross-species extraction in fragmented assemblies like the ones obtained from hybridization capture data. Accepted values are decimals from 0 to 1. For more details, read Scipio’s settings.\nThis argument is optional, the default is 0.2.\n--ptd_min_identity Minimum percentage of identity to the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 65.\n--ptd_min_coverage Minimum percentage of coverage of the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 20.\n--ptd_depth_tolerance Allow plastidial contigs with a minimum depth equal to the median depth divided by this number and a maximum depth equal to the median depth multipled by this number. This median depth is calculated only from the contigs with hits to the plastidial proteins.\nThis argument is optional, the default is 10.\nMitochondrial proteins (Scipio) -m, --mit_refs The reference set of mitochondrial proteins to search and extract from the assemblies. The options available are:\nSeedPlantsMIT = Set of mitochondrial proteins that spans all Seed Plants (curated by us). Alternatively, you can provide the path to a FASTA file (e.g. -p my_refs/my_mitome_prots.fa) that includes your own coding references either in nucleotide or aminoacid. If you provide a nucleotide file, please also specify the translation table to be used, otherwise Captus will translate it using --mit_transtable 1, the “Standard code” which is the genetic code used by plant mitochondria. See the complete list of translation tables.\nThis argument is optional and has no default.\n--mit_transtable If you provide a nucleotide file for extraction you can specify the genetic code to translate it.\nThis argument is optional, the default is 1 (= the “Standard code”. See the complete list of translation tables).\n--mit_min_score Keep hits to the reference proteins that have at least this Scipio score. The default has been optimized to perform cross-species extraction in fragmented assemblies like the ones obtained from hybridization capture data. Accepted values are decimals from 0 to 1. For more details, read Scipio’s settings.\nThis argument is optional, the default is 0.2.\n--mit_min_identity Minimum percentage of identity to the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 65.\n--mit_min_coverage Minimum percentage of coverage of the reference protein for a hit to be retained. Accepted values are any number between 0 and 100. For more details, read Scipio’s settings.\nThis argument is optional, the default is 20.\n--mit_depth_tolerance Allow mitochondrial contigs with a minimum depth equal to the median depth divided by this number and a maximum depth equal to the median depth multipled by this number. This median depth is calculated only from the contigs with hits to the mitochondrial proteins.\nThis argument is optional, the default is 10.\nMiscellaneous DNA markers (BLAT) -d, --dna_refs Path to a FASTA nucleotide file of miscellaneous DNA references. You can include non-coding regions, complete genes (exons + introns), complete mRNAS (including UTRs), etc.\nThis argument is optional and has no default.\n--dna_min_identity Minimum percentage of identity to the reference sequence for a hit to be retained. Accepted values are any number between 0 and 100.\nThis argument is optional, the default is 80.\n--dna_min_coverage Minimum percetange of coverage of the reference sequence for a hit to be retained. Accepted values are any number between 0 and 100.\nThis argument is optional, the default is 20.\n--dna_min_coverage Allow contigs with a minimum depth equal to the median depth divided by this number and a maximum depth equal to the median depth multipled by this number. This median depth is calculated only from the contigs with hits to the miscellaneous DNA reference targets.\nThis argument is optional, the default is 10.\nAssemblies clustering (MMSeqs2) Most contigs in your assemblies will not contain hits to your references, that means that many potentially useful markers usually remain unused and unexplored. With this feature you can cluster your unused contigs across samples to find new markers that can complement your phylogenomic dataset.\n-c, --cluster_leftovers Enable MMseqs2 clustering across samples for the contigs that had no hits to the reference markers. A new miscellaneous DNA reference is built from the best representative of each cluster in order to perform a miscellaneous DNA marker extraction.\n--mmseqs_method Select MMseqs2’s clustering algorithm. Valid options are:\neasy-linclust = Fast linear time (for huge datasets), less sensitive clustering easy-cluster = Sensitive homology search (slower) This argument is optional, the default is easy-linclust.\n--cl_mode Select MMseqs2’s clustering mode. Valid options are:\n0 = Greedy set cover 1 = Connected component 2 = Greedy incremental (analogous to CD-HIT) This argument is optional, the default is 2.\n--cl_sensitivity MMseqs2 sensitivity, from 1 to 7.5, only applicable when using ’easy-cluster’. Common reference points are: 1 (faster), 4 (fast), 7.5 (sens).\nThis argument is optional, the default is 7.5.\n--cl_min_identity Minimum percentage of similarity between sequences within a cluster. Accepted values are any number between 75 and 100. Since Captus will perform a Miscellaneous DNA marker extraction using as reference the best representative of each cluster, it is convenient to set --cl_min_identity a little lower than --dna_min_identity.\nThis identity threshold only affects the clustering used for the creation of the new reference of DNA markers, the actual marker extraction still depends of dna_min_identity.\nThis argument is optional, the default is auto (= 99% of dna_min_identity).\n--cl_seq_id_mode Select MMseqs2’s sequence identity mode. Valid options are:\n0 = Alignment length 1 = Shorter sequence 2 = Longer sequence This argument is optional, the default is 1.\n--cl_min_coverage For a sequence to be included in a cluster, this percentage of its length has to be matched by the longest sequence in the cluster. Accepted values are number between 0 and 100.\nThis only affects the clustering used for the creation of the new reference of DNA markers, the actual marker extraction still depends of dna_min_coverage.\nThis argument is optional, the default is 80.\n--cl_cov_mode Select MMseqs2’s sequence coverage mode. Valid options are:\n0 = Bidirectional (query and target) 1 = Target 2 = Query 3 = Target-in-query This argument is optional, the default is 1.\n--cl_max_seq_len Do not cluster sequences longer than this length in bp, the maximum allowed by MMseqs2 is 65535. Use the value 0 to disable this filter.\nThis argument is optional, the default is 20000.\n--cl_rep_min_len After clustering is finished, only accept cluster representatives of at least this length to be part of the new miscellaneous DNA reference. This avoids the creation of very short locus alignments. Use the value 0 to disable this filter.\nThis argument is optional, the default is 500.\n--cl_min_samples Minimum number of samples per cluster.\nThis argument is optional, the default is auto (= 30% of the total number of samples or at least 4).\n--cl_max_copies Maximum average number of sequences per sample in a cluster. Helpful for excluding excessively paralogous loci.\nThis argument is optional, the default is 5.\n--cl_tmp_dir Path where to create the temporary directory for MMseqs2. Clustering can become slow when done on external drives, set this location to an internal drive.\nThis argument is optional, the default is $HOME.\nOther --scipio_path, --blat_path If you have installed your own copies of Scipio, BLAT you can provide the full path to those copies.\nThese arguments are optional, the default is to use the bundled copies of these programs.\n--mmseqs_path, --mafft_path If you have installed your own copy of MMSeqs2 or MAFFT you can provide the full path to that copy.\nThis argument is optional, the default is mmseqs and mafft respectively.\n--ram, --threads, --concurrent, --debug, --show_less See Parallelization (and other common options)\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (18.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Options",
    "uri": "/captus.docs/assembly/extract/options/"
  },
  {
    "content": "For this example we will use the directory 03_extractions previously created with the extract module. We run the following Captus command to collect markers across samples and align them:\ncaptus align -e 03_extractions_CAP/ -o 04_alignments_CAP -m ALL -f ALL After the run is finished we should see a new directory called 04_alignments with the following structure and files:\nComplete structure of the alignment output directory 1. 01_unaligned This directory contains the unaligned FASTA files corresponding to each marker that were gathered from the extractions directory. The files are organized in subdirectories, first by marker type and then by format.\n2. 02_untrimmed This directory contains the aligned FASTA files corresponding to each file in the 01_unaligned directory. The files are organized in subdirectories, first by filtering strategy, then by marker type, and finally by format. The subdirectory structure is identical to the one inside the 03_trimmed directory (see 4 to 15 below). 3. 03_trimmed All the files present in the 02_untrimmed directory are trimmed using ClipKIT which removes columns that are mostly empty (see options --clipkit_algorithm, --clipkit_gaps), then Captus removes sequences that are too short after trimming (--min_coverage). The files are organized in subdirectories, first by filtering strategy, then by marker type, and finally by format. The subdirectory structure is identical to the one inside the 02_untrimmed directory (see 4 to 15 below). 4. 01_unfiltered_w_refs This directory contains the alignments before performing any filtering. All the reference sequences selected by at least a sample will be present as well as all the paralogs per sample. The files are organized in subdirectories, first by marker type and then by format.\n5. 02_naive_w_refs This directory contains the alignments where paralogs have been filtered by the naive method, which consists in simply keeping the best hit per sample (hit ranked as 00). All the reference sequences selected by at least a sample will still be present. The files are organized in subdirectories, first by marker type and then by format. 6. 03_informed_w_refs This directory contains the alignments where paralogs have been filtered by the informed method. Under this strategy, Captus compares every copy to the most commonly used reference sequence (sequence ABCD-3400 in the figure) and retains the copy with the highest similarity to that reference, regardless of its paralog ranking (in the figure, Sample1 and Sample4 whose selected copies had paralog rankings of 01 and 02 respectively). All the reference sequences selected by at least a sample will still be present. The files are organized in subdirectories, first by marker type and then by format. 7. 04_unfiltered, 05_naive, 06_informed These contain equivalent alignments to directories 01_unfiltered_w_refs, 02_naive_w_refs, and 03_informed_w_refs respectively, but excluding the reference sequences. In most cases you will estimate phylogenies from the trimmed versions of these alignments.\n8. 01_coding_NUC, 02_coding_PTD, 03_coding_MIT These directories contain the aligned coding markers from the NUClear, PlasTiDial, and MITochondrial genomes respectively.\nThe alignments are presented in four formats: protein sequence (coding_AA), coding sequence in nucleotide (coding_NT), exons and introns concatenated (genes), and the concatenation of exons and introns flanked by a fixed length of sequence (genes_flanked):\n9. 01_AA This directory contains the protein alignments (AA in the figure above) of the extracted markers gathered across samples. One FASTA file per marker, with extension .faa.\n10. 02_NT This directory contains the alignments of coding sequence in nucleotides (NT in the figure above) of the extracted markers gathered across samples. One FASTA file per marker, with extension .fna.\n11. 03_genes This directory contains the alignments of gene sequence (exons + introns) in nucleotides (GE in the figure above) of the extracted markers gathered across samples. One FASTA file per marker, with extension .fna.\n12. 04_genes_flanked This directory contains the alignments of flanked gene sequence in nucleotides (GF in the figure above) of the extracted markers gathered across samples. One FASTA file per marker, with extension .fna.\n13. 04_misc_DNA, 05_clusters These directories contain the aligned miscellaneous DNA markers, either from a DNA custom set of references or from the CLusteRing resulting from using the option --cluster_leftovers during the extraction step.\nThe alignments are presented in two formats: matching DNA segments (matches), and the matched segments including flanks and other intervening segments not present in the reference (matches_flanked).\n14. 01_matches This directory contains the alignments of DNA sequence matches (MA in the figure above) for the extracted markers gathered across samples. One FASTA file per marker, with extension .fna.\n15. 02_matches_flanked This directory contains the alignments of DNA sequence matches (MF in the figure above) including flanks and intervening segments not present in the references for the extracted markers gathered across samples. One FASTA file per marker, with extension .fna.\n16. captus-align_paralogs.tsv A tab-separated-values table recording which copy was selected during the informed filtering of paralogs.\nInformation included in the table Column Description marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. format_filtered Alignment format used for identity comparison and filtering. For protein references, if the reference is provided both in aminoacids and nucleotides, the nucleotide format is used. locus Name of the locus. ref Name of most common the reference observed in the alignment. sample Name of the sample. hit Paralog ranking. sequence Name of the sequence as it appears in the alignments. length Lenght of the sequence in aminoacids if format_filtered is AA, or in nucleotides if format_filtered is NT identity Identity of the sequence to the ref sequence, over the overlapping segment, ignoring internal gaps. paralog_score (length / length of ref) * (identity / 100), the highest score decides the selected copy. accepted Whether the copy is accepted (TRUE) or not (FALSE). 17. captus-align_alignments.tsv A tab-separated-values table recording alignment statistics for each of the alignments produced.\nInformation included in the table Column Description path Absolute path to the alignment file. trimmed Whether the alignment has been trimmed (TRUE) or not (FALSE). paralog_filter Filtering strategy applied to the file. Possible values are unfiltered, naive, or informed. with_refs Whether the file still contains the reference sequences (TRUE) or they have been removed (FALSE). marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. format Alignment format. Possible values are AA,NT,GE,GF,MA,MF. locus Name of the locus. seqs Number of sequences in the alignment. samples Number of samples represented in the alignment. The number can be smaller than seqs if the alignment has paralogs. avg_copies seqs / samples sites Alignment length. informative Number of parsimony-informative-sites in the alignment. informativeness (informative / sites) * 100 uninformative constant + singleton constant Number of invariant sites in the alignment. singleton Number of sites with variaton in a single sequence. paterns Number of unique columns, for a detailed explanation see IQ-TREE’s F.A.Q.: What are the differences between alignment columns/sites and patterns?. avg_pid Average pairwise identity between sequences in the alignment. missingness Proportion of missing data (-, N, X, ?, ., ~) in the alignment. gc gc_codon_p1 gc_codon_p2 gc_codon_p3 18. captus-align_samples.tsv A tab-separated-values table recording sample statistics across the different filtering and trimming stages, as well as marker types and formats.\nInformation included in the table Column Description sample Sample name. stage_marker_format Trimming stage / Filtering strategy / Marker type / Format. locus Name of the locus. len_total len_gapped len_ungapped cov_gapped Coverage of the sequence relative to alignment length, including internal gaps. cov_ungapped Coverage of the sequence relative to alignment length, excluding internal gaps. ambigs pct_ambig Percentage of ambiguities in the sequence, excluding gaps. gc gc_codon_p1 gc_codon_p2 gc_codon_p3 num_copies Number of copies in the alignment. 19. captus-align_astral-pro.tsv ASTRAL-Pro requires a tab-separated-values file for mapping the names of the paralog sequence names (first column) to the name of the sample (second column). Captus produces this file automatically.\nExample GenusA_speciesA_CAP\tGenusA_speciesA_CAP GenusA_speciesA_CAP__00\tGenusA_speciesA_CAP GenusA_speciesA_CAP__01\tGenusA_speciesA_CAP GenusA_speciesA_CAP__02\tGenusA_speciesA_CAP GenusA_speciesA_CAP__03\tGenusA_speciesA_CAP GenusA_speciesA_CAP__04\tGenusA_speciesA_CAP GenusA_speciesA_CAP__05\tGenusA_speciesA_CAP GenusB_speciesB_CAP\tGenusB_speciesB_CAP GenusB_speciesB_CAP__00\tGenusB_speciesB_CAP GenusB_speciesB_CAP__01\tGenusB_speciesB_CAP GenusB_speciesB_CAP__02\tGenusB_speciesB_CAP GenusC_speciesC_CAP\tGenusC_speciesC_CAP GenusC_speciesC_CAP__00\tGenusC_speciesC_CAP GenusC_speciesC_CAP__01\tGenusC_speciesC_CAP GenusC_speciesC_CAP__02\tGenusC_speciesC_CAP GenusC_speciesC_CAP__03\tGenusC_speciesC_CAP GenusC_speciesC_CAP__04\tGenusC_speciesC_CAP GenusC_speciesC_CAP__05\tGenusC_speciesC_CAP GenusD_speciesD_CAP\tGenusD_speciesD_CAP GenusD_speciesD_CAP__00\tGenusD_speciesD_CAP GenusD_speciesD_CAP__01\tGenusD_speciesD_CAP GenusD_speciesD_CAP__02\tGenusD_speciesD_CAP GenusD_speciesD_CAP__03\tGenusD_speciesD_CAP GenusD_speciesD_CAP__04\tGenusD_speciesD_CAP GenusD_speciesD_CAP__05\tGenusD_speciesD_CAP 20. captus-align_report.html This is the final Aligment report, summarizing alignment statistics across all processing stages, marker types, and formats.\n21. captus-align.log This is the log from Captus, it contains the command used and all the information shown during the run. Even if the option --show_more was disabled, the log will contain all the extra detailed information that was hidden during the run.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Output Files",
    "uri": "/captus.docs/assembly/align/output/"
  },
  {
    "content": "For this example we will use the directory 01_clean_reads previously created with the clean module. We run the following Captus command to assemble our cleaned reads:\ncaptus assemble --reads 01_clean_reads --sample_reads_target 1000000 --max_contig_gc 60.0 We are including the option --sample_reads_target 1000000 to show the expected output even though this option will not be very commonly used. Additionally, the option --max_contig_gc 60.0 is used to filter contigs with GC content over 60% after assembly, the filtered contigs are always saved to removed_contigs.fasta in case the filtering has to be repeated after changing the thresholds.\nAfter the run is finished we should see a new directory called 02_assemblies with the following structure and files:\n1. [sample]__captus-asm A subdirectory ending in __captus-asm is created to contain the assembly of each sample separately (S1, S2, S3, and S4 in the image).\n2. 00_subsampled_reads This directory is only created when the option --sample_reads_target is used. It contains the subsampled reads in FASTQ format that were used for the assembly.\nExample 3. 01_assembly This directory contains the FASTA and FASTG assembly files as well as assembly statistics and logs.\n4. assembly.fasta The main assembly file in FASTA format, this file contains the contigs assembled by MEGAHIT and filtered according --max_contig_gc and --min_contig_depth. The sequence headers are modified by Captus to resemble the headers produced by the assembler Spades.\nExample 5. assembly_graph.fastg The assembly graph in FASTG format. This file can be explored in Bandage or similar software which are able to plot the connections between contigs, loops, circular segments, etc. The graph is based on the original MEGAHIT assembly prior to filtering.\nExample 6. megahit_brief.log, megahit_full.log MEGAHIT program logs, the brief version contains just the screen output from each MEGAHIT run.\nExample megahit.brief.log\nCaptus' MEGAHIT Command: megahit -1 /Volumes/Shuttle500G/for_docs_output/02_assemblies/GenusA_speciesA_CAP__captus-asm/00_subsampled_reads/GenusA_speciesA_CAP_R1.fq.gz -2 /Volumes/Shuttle500G/for_docs_output/02_assemblies/GenusA_speciesA_CAP__captus-asm/00_subsampled_reads/GenusA_speciesA_CAP_R2.fq.gz --min-count 2 --k-list 31,39,47,63,79,95,111,127,143,159,175 --merge-level 20,0.95 --prune-level 2 --memory 8504035246 --num-cpu-threads 4 --out-dir /Volumes/Shuttle500G/for_docs_output/02_assemblies/GenusA_speciesA_CAP__captus-asm/01_assembly --min-contig-len 182 --tmp-dir /Users/emortiz/captus_megahit_tmp 2022-04-08 01:09:30 - MEGAHIT v1.2.9 2022-04-08 01:09:30 - Using megahit_core with POPCNT and BMI2 support 2022-04-08 01:09:30 - Convert reads to binary library 2022-04-08 01:09:31 - b'INFO sequence/io/sequence_lib.cpp : 77 - Lib 0 (/Volumes/Shuttle500G/for_docs_output/02_assemblies/GenusA_speciesA_CAP__captus-asm/00_subsampled_reads/GenusA_speciesA_CAP_R1.fq.gz,/Volumes/Shuttle500G/for_docs_output/02_assemblies/GenusA_speciesA_CAP__captus-asm/00_subsampled_reads/GenusA_speciesA_CAP_R2.fq.gz): pe, 720090 reads, 151 max length' 2022-04-08 01:09:31 - b'INFO utils/utils.h : 152 - Real: 1.3603\\tuser: 0.6603\\tsys: 0.2130\\tmaxrss: 64000000' 2022-04-08 01:09:31 - Start assembly. Number of CPU threads 4 2022-04-08 01:09:31 - k list: 31,39,47,63,79,95,111,127,143,159,175 2022-04-08 01:09:31 - Memory used: 8504035246 2022-04-08 01:09:31 - Extract solid (k+1)-mers for k = 31 2022-04-08 01:09:41 - Build graph for k = 31 2022-04-08 01:09:43 - Assemble contigs from SdBG for k = 31 2022-04-08 01:09:46 - Local assembly for k = 31 2022-04-08 01:09:55 - Extract iterative edges from k = 31 to 39 2022-04-08 01:09:57 - Build graph for k = 39 2022-04-08 01:09:58 - Assemble contigs from SdBG for k = 39 2022-04-08 01:10:00 - Local assembly for k = 39 2022-04-08 01:10:15 - Extract iterative edges from k = 39 to 47 2022-04-08 01:10:17 - Build graph for k = 47 2022-04-08 01:10:18 - Assemble contigs from SdBG for k = 47 2022-04-08 01:10:20 - Local assembly for k = 47 2022-04-08 01:10:39 - Extract iterative edges from k = 47 to 63 2022-04-08 01:10:41 - Build graph for k = 63 2022-04-08 01:10:42 - Assemble contigs from SdBG for k = 63 2022-04-08 01:10:44 - Local assembly for k = 63 2022-04-08 01:11:03 - Extract iterative edges from k = 63 to 79 2022-04-08 01:11:05 - Build graph for k = 79 2022-04-08 01:11:06 - Assemble contigs from SdBG for k = 79 2022-04-08 01:11:08 - Local assembly for k = 79 2022-04-08 01:11:28 - Extract iterative edges from k = 79 to 95 2022-04-08 01:11:30 - Build graph for k = 95 2022-04-08 01:11:31 - Assemble contigs from SdBG for k = 95 2022-04-08 01:11:33 - Local assembly for k = 95 2022-04-08 01:11:49 - Extract iterative edges from k = 95 to 111 2022-04-08 01:11:50 - Build graph for k = 111 2022-04-08 01:11:51 - Assemble contigs from SdBG for k = 111 2022-04-08 01:11:53 - Local assembly for k = 111 2022-04-08 01:12:08 - Extract iterative edges from k = 111 to 127 2022-04-08 01:12:09 - Build graph for k = 127 2022-04-08 01:12:10 - Assemble contigs from SdBG for k = 127 2022-04-08 01:12:12 - Local assembly for k = 127 2022-04-08 01:12:26 - Extract iterative edges from k = 127 to 143 2022-04-08 01:12:26 - Build graph for k = 143 2022-04-08 01:12:27 - Assemble contigs from SdBG for k = 143 2022-04-08 01:12:29 - Local assembly for k = 143 2022-04-08 01:12:40 - Extract iterative edges from k = 143 to 159 2022-04-08 01:12:40 - Build graph for k = 159 2022-04-08 01:12:41 - Assemble contigs from SdBG for k = 159 2022-04-08 01:12:43 - Local assembly for k = 159 2022-04-08 01:12:53 - Extract iterative edges from k = 159 to 175 2022-04-08 01:12:54 - Build graph for k = 175 2022-04-08 01:12:54 - Assemble contigs from SdBG for k = 175 2022-04-08 01:12:56 - Merging to output final contigs 2022-04-08 01:12:56 - 1850 contigs, total 2031858 bp, min 182 bp, max 26295 bp, avg 1098 bp, N50 1616 bp 2022-04-08 01:12:56 - ALL DONE. Time elapsed: 206.394586 seconds 7. 01_salmon_quant This directory contains the results of mapping the reads back to the assembled contigs using Salmon. It is not created when --ignore_mapping is used.\n8. salmon.log Salmon logs, combined for the indexing and quantification steps.\n9. removed_contigs.fasta This file is created after the filtering by GC and/or depth is finished (same format as in 4).\n10. contigs_depth.tsv Table containing depth statistics and contig names with the original depth estimated by MEGAHIT and then recalculated with Salmon.\nInformation included in the table Column Description megahit_contig_name Original contig name from MEGAHIT megahit_depth Depth of coverage contained in megahit_contig_name length Length of the contig in bp salmon_contig_name Contig name with depth of coverage calculated by Salmon salmon_num_reads Estimated number of reads mapping to the contig according to Salmon salmon_depth read length (multiplied by 2 if reads are paired-end) * salmon_num_reads / length 11. assembly_stats.tsv Assembly statistics, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering num_contigs Number of contigs pct_contigs_1kbp Percentage of contigs over 1kbp pct_contigs_2kbp Percentage of contigs over 2kbp pct_contigs_5kbp Percentage of contigs over 5kbp pct_contigs_10kbp Percentage of contigs over 10kbp pct_contigs_20kbp Percentage of contigs over 20kbp pct_contigs_50kbp Percentage of contigs over 50kbp total_length Cumulative length of all contigs in bp pct_lengt_1kbp Percentage of total assembly length in contigs over 1kbp pct_lengt_2kbp Percentage of total assembly length in contigs over 2kbp pct_lengt_5kbp Percentage of total assembly length in contigs over 5kbp pct_lengt_10kbp Percentage of total assembly length in contigs over 10kbp pct_lengt_20kbp Percentage of total assembly length in contigs over 20kbp pct_lengt_50kbp Percentage of total assembly length in contigs over 50kbp shortest_contig Length of shortest contig in bp longest_contig Length of longest contig in bp avg_length Average contig length in bp median_length Median contig length in bp avg_depth Average contig depth median_depth Median contig depth gc Average contig GC content N50 Assembly N50 in bp N75 Assembly N75 in bp L50 Assembly L50 in number of contigs L75 Assembly L75 in number of contigs 12. depth_stats.tsv Depth statistics, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering depth_bin Upper limit of the depth bin (lower limit given by the previous depth bin value) length Sum of lengths of the contigs inside the depth_bin fraction Sum of lengths of the contigs inside the depth_bin as a fraction of the total length num_contigs Number of contigs inside the depth_bin 13. length_stats.tsv Length statistics, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering length_bin Upper limit of the length bin (lower limit given by the previous length bin value) length Sum of lengths of the contigs inside the length_bin fraction Sum of lengths of the contigs inside the length_bin as a fraction of the total length num_contigs Number of contigs inside the length_bin 14. captus-assemble_assembly_stats.tsv Assembly statistics compiled across all samples, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering num_contigs Number of contigs pct_contigs_1kbp Percentage of contigs over 1kbp pct_contigs_2kbp Percentage of contigs over 2kbp pct_contigs_5kbp Percentage of contigs over 5kbp pct_contigs_10kbp Percentage of contigs over 10kbp pct_contigs_20kbp Percentage of contigs over 20kbp pct_contigs_50kbp Percentage of contigs over 50kbp total_length Cumulative length of all contigs in bp pct_lengt_1kbp Percentage of total assembly length in contigs over 1kbp pct_lengt_2kbp Percentage of total assembly length in contigs over 2kbp pct_lengt_5kbp Percentage of total assembly length in contigs over 5kbp pct_lengt_10kbp Percentage of total assembly length in contigs over 10kbp pct_lengt_20kbp Percentage of total assembly length in contigs over 20kbp pct_lengt_50kbp Percentage of total assembly length in contigs over 50kbp shortest_contig Length of shortest contig in bp longest_contig Length of longest contig in bp avg_length Average contig length in bp median_length Median contig length in bp avg_depth Average contig depth median_depth Median contig depth gc Average contig GC content N50 Assembly N50 in bp N75 Assembly N75 in bp L50 Assembly L50 in number of contigs L75 Assembly L75 in number of contigs 15. captus-assemble_depth_stats.tsv Depth statistics compiled across all samples, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering depth_bin Upper limit of the depth bin (lower limit given by the previous depth bin value) length Sum of lengths of the contigs inside the depth_bin fraction Sum of lengths of the contigs inside the depth_bin as a fraction of the total length num_contigs Number of contigs inside the depth_bin 16. captus-assemble_length_stats.tsv Length statistics compiled across all samples, before and after filtering:\nInformation included in the table Column Description sample_name Name of the sample stage Before or After filtering length_bin Upper limit of the length bin (lower limit given by the previous length bin value) length Sum of lengths of the contigs inside the length_bin fraction Sum of lengths of the contigs inside the length_bin as a fraction of the total length num_contigs Number of contigs inside the length_bin 17. captus-assemble_report.html This is the final Assembly report, summarizing statistics across all samples assembled.\n18. captus-assemble.log This is the log from Captus, it contains the command used and all the information shown during the run. If the option --show_less was enabled, the log will also contain all the extra detailed information that was hidden during the run.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Output Files",
    "uri": "/captus.docs/assembly/assemble/output/"
  },
  {
    "content": "Imagine we start with a directory called 00_raw_reads with the following content:\nWe have a samples with different data types, to distinguish them we added _CAP to the samples where hybridization-capture was used, _WGS for high-coverage whole genome sequencing, _RNA for RNA-Seq reads, and _GSK for genome skimming data (notice also the difference in file sizes). For this example, we only want to clean the samples in red rectangles corresponding to capture data. We run the following Captus command:\ncaptus clean --reads ./00_raw_reads/*_CAP_R?.fq.gz Notice we are using default settings, the only required argument is the location of the raw reads. The output was written to a new directory called 01_clean_reads. Let’s take a look at the contents:\n1. 00_adaptors_trimmed This is an intermediate directory that contains the FASTQ files without adaptors, prior to quality-trimming and filtering. The directory also stores bbduk.sh commands and logs for the adaptor trimming stage. If the option --keep_all was enabled the FASTQs from this intermediate are kept after the run, otherwise they are deleted. Example [sample].round1.log\nCaptus' BBDuk Command for BOTH rounds: bbduk.sh -Xmx8110m threads=8 ktrim=r minlength=21 interleaved=f trimpairsevenly=t trimbyoverlap=t overwrite=t ref=/software/GitHub/Captus/data/adaptors_combined.fasta in=/tutorial/00_raw_reads/GenusA_speciesA_CAP_R#.fq.gz out=stdout.fq ftr=0 k=21 mink=11 hdist=2 stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round1.stats.txt 2\u003e/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.stdout1.log | bbduk.sh -Xmx8110m threads=8 ktrim=r minlength=21 interleaved=f trimpairsevenly=t trimbyoverlap=t overwrite=t ref=/software/GitHub/Captus/data/adaptors_combined.fasta in=stdin.fq out=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP_R#.fq.gz k=19 mink=9 hdist=1 stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round2.stats.txt 2\u003e/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.stdout2.log ROUND 1 LOG: Executing jgi.BBDuk [-Xmx8110m, threads=8, ktrim=r, minlength=21, interleaved=f, trimpairsevenly=t, trimbyoverlap=t, overwrite=t, ref=/software/GitHub/Captus/data/adaptors_combined.fasta, in=/tutorial/00_raw_reads/GenusA_speciesA_CAP_R#.fq.gz, out=stdout.fq, ftr=0, k=21, mink=11, hdist=2, stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round1.stats.txt] Version 38.95 Set threads to 8 Set INTERLEAVED to false maskMiddle was disabled because useShortKmers=true 0.030 seconds. Initial: Memory: max=8503m, total=8503m, free=8478m, used=25m Added 11201253 kmers; time: 3.185 seconds. Memory: max=8503m, total=8503m, free=7967m, used=536m Input is being processed as paired Started output streams:\t0.044 seconds. Processing time: 8.051 seconds. Input: 733778 reads 110800478 bases. KTrimmed: 20580 reads (2.80%) 393486 bases (0.36%) Trimmed by overlap: 1870 reads (0.25%) 10642 bases (0.01%) Total Removed: 330 reads (0.04%) 404128 bases (0.36%) Result: 733448 reads (99.96%) 110396350 bases (99.64%) Time: 11.312 seconds. Reads Processed: 733k 64.87k reads/sec Bases Processed: 110m 9.79m bases/sec [sample].round1.stats.txt\n#File\t/tutorial/00_raw_reads/GenusA_speciesA_CAP_R1.fq.gz\t/tutorial/00_raw_reads/GenusA_speciesA_CAP_R2.fq.gz #Total\t733778 #Matched\t11733\t1.59898% #Name\tReads\tReadsPct Reverse_adaptor\t1899\t0.25880% PhiX_read2_adaptor\t1109\t0.15114% TruSeq_Adaptor_Index_1_6\t1018\t0.13873% pcr_dimer\t675\t0.09199% Forward_filter\t608\t0.08286% Illumina 3p RNA Adaptor\t595\t0.08109% I5_Nextera_Transposase_1\t475\t0.06473% PhiX_read1_adaptor\t468\t0.06378% Nextera_LMP_Read2_External_Adaptor\t446\t0.06078% Reverse_filter\t419\t0.05710% . . . TruSeq_Adaptor_Index_9\t1\t0.00014% [sample].round2.log\nCaptus' BBDuk Command for BOTH rounds: bbduk.sh -Xmx8110m threads=8 ktrim=r minlength=21 interleaved=f trimpairsevenly=t trimbyoverlap=t overwrite=t ref=/software/GitHub/Captus/data/adaptors_combined.fasta in=/tutorial/00_raw_reads/GenusA_speciesA_CAP_R#.fq.gz out=stdout.fq ftr=0 k=21 mink=11 hdist=2 stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round1.stats.txt 2\u003e/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.stdout1.log | bbduk.sh -Xmx8110m threads=8 ktrim=r minlength=21 interleaved=f trimpairsevenly=t trimbyoverlap=t overwrite=t ref=/software/GitHub/Captus/data/adaptors_combined.fasta in=stdin.fq out=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP_R#.fq.gz k=19 mink=9 hdist=1 stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round2.stats.txt 2\u003e/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.stdout2.log ROUND 2 LOG: Executing jgi.BBDuk [-Xmx8110m, threads=8, ktrim=r, minlength=21, interleaved=f, trimpairsevenly=t, trimbyoverlap=t, overwrite=t, ref=/software/GitHub/Captus/data/adaptors_combined.fasta, in=stdin.fq, out=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP_R#.fq.gz, k=19, mink=9, hdist=1, stats=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP.round2.stats.txt] Version 38.95 Set threads to 8 Set INTERLEAVED to false maskMiddle was disabled because useShortKmers=true Forcing interleaved input because paired output was specified for a single input file. 0.028 seconds. Initial: Memory: max=8503m, total=8503m, free=8478m, used=25m Added 322384 kmers; time: 0.239 seconds. Memory: max=8503m, total=8503m, free=8469m, used=34m Input is being processed as paired Started output streams:\t0.056 seconds. Processing time: 11.134 seconds. Input: 733448 reads 110396350 bases. KTrimmed: 10720 reads (1.46%) 103592 bases (0.09%) Trimmed by overlap: 0 reads (0.00%) 0 bases (0.00%) Total Removed: 18 reads (0.00%) 103592 bases (0.09%) Result: 733430 reads (100.00%) 110292758 bases (99.91%) Time: 11.447 seconds. Reads Processed: 733k 64.07k reads/sec Bases Processed: 110m 9.64m bases/sec [sample].round2.stats.txt\n#File\tstdin.fq #Total\t733448 #Matched\t5386\t0.73434% #Name\tReads\tReadsPct PhiX_read2_adaptor\t781\t0.10648% Forward_filter\t374\t0.05099% I5_Nextera_Transposase_1\t373\t0.05086% Reverse_adaptor\t367\t0.05004% RNA_Adaptor_(RA3)_part_#_15013207\t361\t0.04922% Reverse_filter\t327\t0.04458% PhiX_read1_adaptor\t267\t0.03640% Stop_Oligo_(STP)_8\t249\t0.03395% Nextera_LMP_Read2_External_Adaptor\t215\t0.02931% Illumina 3p RNA Adaptor\t190\t0.02591% . . . I5_Primer_Nextera_XT_Index_Kit_v2_S520\t1\t0.00014% 2. [sample]_R1.fq.gz, [sample]_R2.fq.gz In case of paired-end input we will have a pair of files like in the image, the forward reads are indicated by _R1 and the reverse reads by _R2. Single-end input will only return forward reads. Wikipedia’s entry for the format describes it in more detail. These are the cleaned reads that will be used by the assemble module.\nExample 3. [sample].cleaning.log This file contains the cleaning command used for bbduk.sh as well the data shown as screen output, this and other information is compiled in the Cleaning report. Example Captus' BBDuk Command: bbduk.sh -Xmx16220m threads=8 in=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP_R#.fq.gz out=/tutorial/01_clean_reads/GenusA_speciesA_CAP_R#.fq.gz ref=/software/GitHub/Captus/data/phix174_ill.ref.fa.gz,/software/GitHub/Captus/data/sequencing_artifacts.fasta k=31 hdist=1 qtrim=lr trimq=13 maq=16 ftl=0 ftr=0 minlength=21 maxns=5 ziplevel=5 overwrite=t stats=/tutorial/01_clean_reads/GenusA_speciesA_CAP.cleaning.stats.txt 2\u003e/tutorial/01_clean_reads/GenusA_speciesA_CAP.stdout.log Executing jgi.BBDuk [-Xmx16220m, threads=8, in=/tutorial/01_clean_reads/00_adaptors_trimmed/GenusA_speciesA_CAP_R#.fq.gz, out=/tutorial/01_clean_reads/GenusA_speciesA_CAP_R#.fq.gz, ref=/software/GitHub/Captus/data/phix174_ill.ref.fa.gz,/software/GitHub/Captus/data/sequencing_artifacts.fasta, k=31, hdist=1, qtrim=lr, trimq=13, maq=16, ftl=0, ftr=0, minlength=21, maxns=5, ziplevel=5, overwrite=t, stats=/tutorial/01_clean_reads/GenusA_speciesA_CAP.cleaning.stats.txt] Version 38.95 Set threads to 8 0.018 seconds. Initial: Memory: max=17007m, total=17007m, free=16987m, used=20m Added 8403228 kmers; time: 1.021 seconds. Memory: max=17007m, total=17007m, free=16612m, used=395m Input is being processed as paired Started output streams:\t0.062 seconds. Processing time: 3.655 seconds. Input: 733430 reads 110292758 bases. Contaminants: 0 reads (0.00%) 0 bases (0.00%) QTrimmed: 127322 reads (17.36%) 515529 bases (0.47%) Low quality discards: 13310 reads (1.81%) 1903218 bases (1.73%) Total Removed: 13340 reads (1.82%) 2418747 bases (2.19%) Result: 720090 reads (98.18%) 107874011 bases (97.81%) Time: 4.753 seconds. Reads Processed: 733k 154.32k reads/sec Bases Processed: 110m 23.21m bases/sec 4. [sample].cleaning.stats.txt List of contaminants found by bbduk.sh in the input reads, sorted by abundance. Example #File\t/tutorial/01_clean_reads/00_adaptors_trimmed/GenusX_speciesX_CAP_R1.fq.gz\t/tutorial/01_clean_reads/00_adaptors_trimmed/GenusX_speciesX_CAP_R2.fq.gz #Total\t60621406 #Matched\t25\t0.00004% #Name\tReads\tReadsPct gi|9626372|ref|NC_001422.1| Coliphage phiX174, complete genome\t14\t0.00002% contam_111\t8\t0.00001% contam_32\t1\t0.00000% contam_76\t1\t0.00000% contam_87\t1\t0.00000% 5. 01_qc_stats_before, 02_qc_stats_after These directories contain the results from either Falco or FastQC, organized in a subdirectory per FASTQ file analyzed.\n6. 03_qc_extras This directory contains all the tab-separated-values tables needed to build the Cleaning report. We provide them separately to allow the user more detailed analyses. List of tables produced Table Description adaptor_content.tsv Adaptor content percentages, parsed from Falco’s orFastQC’s output adaptors_round1.tsv Reads/bases after first round of adaptor removal, parsed from bbduk.sh’s logs adaptors_round2.tsv Reads/bases after second round of adaptor removal, parsed from bbduk.sh’s logs contaminants.tsv Contaminant content, compiled from bbduk.sh’s logs per_base_seq_content.tsv Per base sequence content, parsed from Falco’s orFastQC’s output per_base_seq_qual.tsv Per base sequence quality, parsed from Falco’s orFastQC’s output per_seq_gc_content.tsv GC content per sequence, parsed from Falco’s orFastQC’s output per_seq_qual_scores.tsv Per sequence quality scores, parsed from Falco’s orFastQC’s output reads_bases.tsv Reads/bases after quality filtering and contaminant removal, parsed from bbduk.sh’s logs seq_dup_levels.tsv Sequence duplication levels, parsed from Falco’s orFastQC’s output seq_len_dist.tsv Sequence length distribution, parsed from Falco’s orFastQC’s output 7. captus-clean_report.html This is the final Cleaning report, summarizing statistics across all samples analyzed.\n8. captus-clean.log This is the log from Captus, it contains the command used and all the information shown during the run. If the option --show_less was enabled, the log will also contain all the extra detailed information that was hidden during the run.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Output Files",
    "uri": "/captus.docs/assembly/clean/output/"
  },
  {
    "content": "For this example we will use the directory 02_assemblies previously created with the assemble module. We run the following Captus command to search and extract our reference markers from the assemblies:\ncaptus extract -a 02_assemblies \\ -n Angiosperms353 \\ -p SeedPlantsPTD \\ -m SeedPlantsMIT \\ -d noncoding_DNA.fasta \\ -c \\ --max_loci_files 500 Warning Notice the addition of option --max_loci_files 500, which is used only for showing the output directories containing separate FASTA file per marker (3’, 4’, 5’, 6’, 13’, and 14’ in the image below, not created by default), we don’t recommend using this option in your runs since it will unnecesarily create large numbers of small FASTA files which would have to be concatenated again anyways during the alignment step.\nYou can read more about the option here: –max_loci_files\nAfter the run is finished we should see a new directory called 03_extractions with the following structure and files:\n1. [SAMPLE_NAME]__captus-ext A subdirectory ending in __captus-ext is created to contain the extracted markers of each sample separately (S1, S2, S3, and S4 in the image).\n2. 01_coding_NUC, 02_coding_PTD, 03_coding_MIT These directories contain the extracted coding markers from the NUClear, PlasTiDial, and MITochondrial genomes respectively.\nThe markers are presented in four formats: protein sequence (coding_AA), coding sequence in nucleotide (coding_NT), exons and introns concatenated (genes), and the concatenation of exons and introns flanked by a fixed length of sequence (genes_flanked):\n3. [MARKER_TYPE]_coding_AA.faa, 01_AA Coding sequence in aminoacids. Prefixes can be NUC, PTD, or MIT. For details on sequence headers see FASTA headers explanation.\nExample 4. [MARKER_TYPE]_coding_NT.fna, 02_NT Coding sequence in nucleotides, a.k.a. CDS. Prefixes can be NUC, PTD, or MIT. For details on sequence headers see FASTA headers explanation.\nExample 5. [MARKER_TYPE]_genes.fna, 03_genes Gene sequence (exons in capital letters + introns in lowercase letters) in nucleotides. A contig connector of 50 n characters is included when the protein match spans more than a single contig. Prefixes can be NUC, PTD, or MIT. For details on sequence headers see FASTA headers explanation.\nExample 6. [MARKER_TYPE]_genes_flanked.fna, 04_genes_flanked Gene sequence (exons in capital letters + introns in lowercase letters) plus additional flanking sequence in lowercase nucleotides. A contig connector of 50 n characters is included when the protein match spans more than a single contig. Prefixes can be NUC, PTD, or MIT. For details on sequence headers see FASTA headers explanation.\nExample 7. [MARKER_TYPE]_contigs_list.txt List of contig names that had protein hits. Prefixes can be NUC, PTD, or MIT.\nExample NODE_138_length_18304_cov_18.0000_k_175_flag_1 NODE_635_length_5337_cov_17.0000_k_175_flag_1 NODE_46_length_16959_cov_19.0000_k_175_flag_1 NODE_321_length_4728_cov_10.0000_k_175_flag_1 NODE_760_length_19021_cov_17.9856_k_175_flag_0 NODE_621_length_11511_cov_11.9845_k_175_flag_0 NODE_965_length_6331_cov_15.0000_k_175_flag_1 NODE_948_length_26295_cov_58.0000_k_175_flag_0 NODE_1726_length_1438_cov_9.0000_k_175_flag_1 NODE_210_length_2896_cov_9.9471_k_175_flag_0 NODE_677_length_10733_cov_14.0000_k_175_flag_1 NODE_996_length_2375_cov_11.0000_k_175_flag_1 NODE_1837_length_366_cov_3.0000_k_175_flag_1 NODE_1647_length_529_cov_7.0000_k_175_flag_1 NODE_792_length_4384_cov_17.0000_k_175_flag_1 NODE_1378_length_5491_cov_21.0000_k_175_flag_1 NODE_602_length_14961_cov_47.0000_k_175_flag_1 NODE_1293_length_649_cov_3.0000_k_175_flag_1 NODE_949_length_2240_cov_50.0000_k_175_flag_1 NODE_751_length_2777_cov_34.7909_k_175_flag_0 8. [MARKER_TYPE]_contigs.gff Annotation track in GFF format for protein hits to contigs in assembly. Prefixes can be NUC, PTD, or MIT.\nSee 19. 06_assembly_annotated\n9. [MARKER_TYPE]_recovery_stats.tsv Tab-separated-values table with marker recovery statistics, these are concatenated across marker types and samples and summarized in the final Marker Recovery report. Prefixes can be NUC, PTD, or MIT.\nInformation included in the table Column Description sample_name Name of the sample. marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. locus Name of the locus. ref_name Name of the reference selected for the locus. Relevant when the reference contains multiple sequences per locus like in Angiosperms353 for example. ref_coords Match coordinates with respect to the reference, each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ;. For example: 1-47;48-354,355-449 indicates that a contig contained a segment matching reference coordinates 1-49 and a different contig matched two segments, 48-354 and 355-449 respectively. ref_type Whether the reference is an aminoacid (prot) or nucleotide (nucl) sequence. ref_len_matched Number of residues matched in the reference. hit Paralog ranking, 00 is assigned to the best hit, secondary hits start at 01. pct_recovered Percentage of the total length of the reference sequence that was matched. pct_identity Percentage of sequence identity between the hit and the reference sequence. score Inspired by Scipio’s score: (matches - mismatches) / reference length. wscore Weighted score. When the reference contains multiple sequences per locus, the best-matching reference is decided after normalizing their recovered length across references in the locus and multiplying that value by their respective score, thus producing the wscore. Finally wscore is also penalized by the number of frameshifts (if the marker is coding) and number of contigs used in the assembly of the hit. hit_len Number of residues matched in the sample’s contig(s) plus the length of the flanking sequence. cds_len If ref_type is prot this number represents the number of residues corresponding to coding sequence (i.e. exons). If the ref_type is nucl this field shows NA. intron_len If ref_type is prot this number represents the number of residues corresponding to intervening non-coding sequence segments (i.e. introns). If the ref_type is nucl this field shows NA. flanks_len Number of residues included in the flanking sequence. frameshifts Positions of the corrected frameshifts in the output sequence. If the ref_type is nucl this field shows NA. hit_contigs Number of contigs used to assemble the hit. hit_l50 Least number of contigs in the hit that contain 50% of the recovered length. hit_l90 Least number of contigs in the hit that contain 90% of the recovered length. hit_lg50 Least number of contigs in the hit that contain 50% of the reference locus length. hit_lg90 Least number of contigs in the hit that contain 90% of the reference locus length. ctg_names Name of the contigs used in the reconstruction of the hit. Example: NODE_6256_length_619_cov_3.0000_k_169_flag_1;NODE_3991_length_1778_cov_19.0000_k_169_flag_1, for a hit where two contigs were used. ctg_strands Contig strands (+ or -) provided in the same order as ctg_names. Example: +;- indicates that the contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 was matched in the positive strand while the contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 was matched in the ngeative strand. ctg_coords Match coordinates with respect to the contigs in the sample’s assembly. Each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ; which are provided in the same order as ctg_names and ctg_strands. Example: 303-452;694-1626,301-597 indicates that a single segment was matched in contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 in the + strand with coordinates 303-452, while two segments were matched in contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 in the - strand with coordinates 694-1626 and 301-597 respectively. 10. [MARKER_TYPE]_scipio_final.log Log of the second Scipio’s run, where best references have already been selected (when using multi-sequence per locus references) and only the contigs that had hits durin Scipio’s initial run are used. Prefixes can be NUC, PTD, or MIT.\n11. 00_initial_scipio_[MARKER_TYPE] Directory for Scipio’s initial run results. The directory contains the set of filtered protein references [MARKER_TYPE]_best_proteins.faa (when using multi-sequence per locus references) and the log of Scipio’s initial run [MARKER_TYPE]_scipio_initial.log. Suffixes can be NUC, PTD, or MIT.\n12. 04_misc_DNA, 05_clusters These directories contain the extracted miscellaneous DNA markers, either from a DNA custom set of references or from the CLusteRing resulting from using the option --cluster_leftovers.\nThe markers are presented in two formats: matching DNA segments (matches), and the matched segments including flanks and other intervening segments not present in the reference (matches_flanked).\n13. [MARKER_TYPE]_matches.fna, 01_matches Matches per miscellaneous DNA marker in nucleotides. Prefixes can be DNA or CLR. For details on sequence headers see FASTA headers explanation.\nExample 14. [MARKER_TYPE]_matches_flanked.fna, 02_matches_flanked Matches plus additional flanking sequence per miscellaneous DNA marker in nucleotides. Prefixes can be DNA or CLR. For details on sequence headers see FASTA headers explanation.\nExample 15. [MARKER_TYPE]_contigs_list.txt List of contig names that had miscellaneous DNA marker hits. Prefixes can be DNA or CLR.\nExample NODE_1858_length_3636_cov_14.0000_k_175_flag_1 NODE_2876_length_3179_cov_25.0000_k_175_flag_1 NODE_502_length_5771_cov_37.0000_k_175_flag_1 NODE_347_length_475_cov_2.0000_k_175_flag_1 NODE_1393_length_297_cov_4.0000_k_175_flag_1 NODE_3093_length_960_cov_17.0000_k_175_flag_1 NODE_3265_length_1041_cov_18.0000_k_175_flag_1 16. [MARKER_TYPE]_contigs.gff Annotation track in GFF format for miscellaneous DNA marker hits to contigs in assembly. Prefixes can be DNA or CLR.\nSee 19. 06_assembly_annotated\n17. [MARKER_TYPE]_recovery_stats.tsv Tab-separated-values table with marker recovery statistics, these are concatenated across marker types and samples and summarized in the final Marker Recovery report. Prefixes can be DNA or CLR.\nInformation included in the table Column Description sample_name Name of the sample. marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. locus Name of the locus. ref_name Name of the reference selected for the locus. Relevant when the reference contains multiple sequences per locus like in Angiosperms353 for example. ref_coords Match coordinates with respect to the reference, each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ;. For example: 1-47;48-354,355-449 indicates that a contig contained a segment matching reference coordinates 1-49 and a different contig matched two segments, 48-354 and 355-449 respectively. ref_type Whether the reference is an aminoacid (prot) or nucleotide (nucl) sequence. ref_len_matched Number of residues matched in the reference. hit Paralog ranking, 00 is assigned to the best hit, secondary hits start at 01. pct_recovered Percentage of the total length of the reference sequence that was matched. pct_identity Percentage of sequence identity between the hit and the reference sequence. score Inspired by Scipio’s score: (matches - mismatches) / reference length. wscore Weighted score. When the reference contains multiple sequences per locus, the best-matching reference is decided after normalizing their recovered length across references in the locus and multiplying that value by their respective score, thus producing the wscore. Finally wscore is also penalized by the number of frameshifts (if the marker is coding) and number of contigs used in the assembly of the hit. hit_len Number of residues matched in the sample’s contig(s) plus the length of the flanking sequence. cds_len If ref_type is prot this number represents the number of residues corresponding to coding sequence (i.e. exons). If the ref_type is nucl this field shows NA. intron_len If ref_type is prot this number represents the number of residues corresponding to intervening non-coding sequence segments (i.e. introns). If the ref_type is nucl this field shows NA. flanks_len Number of residues included in the flanking sequence. frameshifts Positions of the corrected frameshifts in the output sequence. If the ref_type is nucl this field shows NA. hit_contigs Number of contigs used to assemble the hit. hit_l50 Least number of contigs in the hit that contain 50% of the recovered length. hit_l90 Least number of contigs in the hit that contain 90% of the recovered length. hit_lg50 Least number of contigs in the hit that contain 50% of the reference locus length. hit_lg90 Least number of contigs in the hit that contain 90% of the reference locus length. ctg_names Name of the contigs used in the reconstruction of the hit. Example: NODE_6256_length_619_cov_3.0000_k_169_flag_1;NODE_3991_length_1778_cov_19.0000_k_169_flag_1, for a hit where two contigs were used. ctg_strands Contig strands (+ or -) provided in the same order as ctg_names. Example: +;- indicates that the contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 was matched in the positive strand while the contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 was matched in the ngeative strand. ctg_coords Match coordinates with respect to the contigs in the sample’s assembly. Each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ; which are provided in the same order as ctg_names and ctg_strands. Example: 303-452;694-1626,301-597 indicates that a single segment was matched in contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 in the + strand with coordinates 303-452, while two segments were matched in contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 in the - strand with coordinates 694-1626 and 301-597 respectively. 18. [MARKER_TYPE]_blat_search.log Log of BLAT’s run. Prefixes can be DNA or CLR.\n19. 06_assembly_annotated The main outputs of this directory are a FASTA file containing all the contigs that had hits to the reference markers called [SAMPLE_NAME]_hit_contigs.fasta as well as an annotation track for those markers called [SAMPLE_NAME]_hit_contigs.gff. You can visualize the annotations in Geneious, for example, by importing the FASTA file and then dropping the GFF file on top: 20. [SAMPLE_NAME]_hit_contigs.fasta This file contains the subset of the contigs assembled by MEGAHIT that had hit to the reference markers. See the red rectangles in 19. 06_assembly_annotated.\nExample 21. [SAMPLE_NAME]_hit_contigs.gff Unified annotation track in GFF format for ALL the marker types found in the assembly’s contigs. See the red rectangles in 19. 06_assembly_annotated.\n22. [SAMPLE_NAME]_recovery_stats.tsv Unified tab-separated-values table with marker recovery statistics from ALL the marker types found in the sample, these are concatenated across samples and summarized in the final Marker Recovery report.\nInformation included in the table Column Description sample_name Name of the sample. marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. locus Name of the locus. ref_name Name of the reference selected for the locus. Relevant when the reference contains multiple sequences per locus like in Angiosperms353 for example. ref_coords Match coordinates with respect to the reference, each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ;. For example: 1-47;48-354,355-449 indicates that a contig contained a segment matching reference coordinates 1-49 and a different contig matched two segments, 48-354 and 355-449 respectively. ref_type Whether the reference is an aminoacid (prot) or nucleotide (nucl) sequence. ref_len_matched Number of residues matched in the reference. hit Paralog ranking, 00 is assigned to the best hit, secondary hits start at 01. pct_recovered Percentage of the total length of the reference sequence that was matched. pct_identity Percentage of sequence identity between the hit and the reference sequence. score Inspired by Scipio’s score: (matches - mismatches) / reference length. wscore Weighted score. When the reference contains multiple sequences per locus, the best-matching reference is decided after normalizing their recovered length across references in the locus and multiplying that value by their respective score, thus producing the wscore. Finally wscore is also penalized by the number of frameshifts (if the marker is coding) and number of contigs used in the assembly of the hit. hit_len Number of residues matched in the sample’s contig(s) plus the length of the flanking sequence. cds_len If ref_type is prot this number represents the number of residues corresponding to coding sequence (i.e. exons). If the ref_type is nucl this field shows NA. intron_len If ref_type is prot this number represents the number of residues corresponding to intervening non-coding sequence segments (i.e. introns). If the ref_type is nucl this field shows NA. flanks_len Number of residues included in the flanking sequence. frameshifts Positions of the corrected frameshifts in the output sequence. If the ref_type is nucl this field shows NA. hit_contigs Number of contigs used to assemble the hit. hit_l50 Least number of contigs in the hit that contain 50% of the recovered length. hit_l90 Least number of contigs in the hit that contain 90% of the recovered length. hit_lg50 Least number of contigs in the hit that contain 50% of the reference locus length. hit_lg90 Least number of contigs in the hit that contain 90% of the reference locus length. ctg_names Name of the contigs used in the reconstruction of the hit. Example: NODE_6256_length_619_cov_3.0000_k_169_flag_1;NODE_3991_length_1778_cov_19.0000_k_169_flag_1, for a hit where two contigs were used. ctg_strands Contig strands (+ or -) provided in the same order as ctg_names. Example: +;- indicates that the contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 was matched in the positive strand while the contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 was matched in the ngeative strand. ctg_coords Match coordinates with respect to the contigs in the sample’s assembly. Each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ; which are provided in the same order as ctg_names and ctg_strands. Example: 303-452;694-1626,301-597 indicates that a single segment was matched in contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 in the + strand with coordinates 303-452, while two segments were matched in contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 in the - strand with coordinates 694-1626 and 301-597 respectively. 23. leftover_contigs.fasta.gz This file contains the subset of the contigs assembled by MEGAHIT that had no hit to the reference markers. The file is compressed to save space. These are the contigs that are used for clustering across samples in order to discover additional homologous markers.\n24. leftover_contigs_after_custering.fasta.gz This file contains the subset of the contigs assembled by MEGAHIT that had no hit to the reference markers or even to the newly discovered markers derived from clusterin. The file is compressed to save space.\n25. captus-extract_refs.json This file stores the paths to all the references used for extraction. This file is necessary so the alignment step can correctly add the references to the final alignments to be used as guides.\nExample { \"NUC\": { \"AA_path\": \"/Users/emortiz/software/GitHub/Captus/data/Angiosperms353.FAA\", \"AA_msg\": \"Angiosperms353 /Users/emortiz/software/GitHub/Captus/data/Angiosperms353.FAA\", \"NT_path\": \"/Users/emortiz/software/GitHub/Captus/data/Angiosperms353.FNA\", \"NT_msg\": \"Angiosperms353 /Users/emortiz/software/GitHub/Captus/data/Angiosperms353.FNA\" }, \"PTD\": { \"AA_path\": \"/Users/emortiz/software/GitHub/Captus/data/SeedPlantsPTD.FAA\", \"AA_msg\": \"SeedPlantsPTD /Users/emortiz/software/GitHub/Captus/data/SeedPlantsPTD.FAA\", \"NT_path\": \"/Users/emortiz/software/GitHub/Captus/data/SeedPlantsPTD.FNA\", \"NT_msg\": \"SeedPlantsPTD /Users/emortiz/software/GitHub/Captus/data/SeedPlantsPTD.FNA\" }, \"MIT\": { \"AA_path\": \"/Users/emortiz/software/GitHub/Captus/data/SeedPlantsMIT.FAA\", \"AA_msg\": \"SeedPlantsMIT /Users/emortiz/software/GitHub/Captus/data/SeedPlantsMIT.FAA\", \"NT_path\": \"/Users/emortiz/software/GitHub/Captus/data/SeedPlantsMIT.FNA\", \"NT_msg\": \"SeedPlantsMIT /Users/emortiz/software/GitHub/Captus/data/SeedPlantsMIT.FNA\" }, \"DNA\": { \"AA_path\": null, \"AA_msg\": null, \"NT_path\": \"/Volumes/Shuttle500G/for_docs_output/nrDNA.fasta\", \"NT_msg\": \"/Volumes/Shuttle500G/for_docs_output/nrDNA.fasta\" }, \"CLR\": { \"AA_path\": null, \"AA_msg\": null, \"NT_path\": \"/Volumes/Shuttle500G/for_docs_output/03_extractions/01_clustering_data/clust_id79.20_cov80.00_captus_clusters_refs.fasta\", \"NT_msg\": \"/Volumes/Shuttle500G/for_docs_output/03_extractions/01_clustering_data/clust_id79.20_cov80.00_captus_clusters_refs.fasta\" } } 26. captus-extract_stats.tsv Unified tab-separated-values table with marker recovery statistics from ALL the markers found in ALL the samples, this table is used to create the final Marker Recovery report. Even though the report is quite useful for visualization you might need to do more complex statistical analysis, this table is the most appropriate output file for such analyses.\nInformation included in the table Column Description sample_name Name of the sample. marker_type Type of marker. Possible values are NUC, PTD, MIT, DNA, or CLR. locus Name of the locus. ref_name Name of the reference selected for the locus. Relevant when the reference contains multiple sequences per locus like in Angiosperms353 for example. ref_coords Match coordinates with respect to the reference, each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ;. For example: 1-47;48-354,355-449 indicates that a contig contained a segment matching reference coordinates 1-49 and a different contig matched two segments, 48-354 and 355-449 respectively. ref_type Whether the reference is an aminoacid (prot) or nucleotide (nucl) sequence. ref_len_matched Number of residues matched in the reference. hit Paralog ranking, 00 is assigned to the best hit, secondary hits start at 01. pct_recovered Percentage of the total length of the reference sequence that was matched. pct_identity Percentage of sequence identity between the hit and the reference sequence. score Inspired by Scipio’s score: (matches - mismatches) / reference length. wscore Weighted score. When the reference contains multiple sequences per locus, the best-matching reference is decided after normalizing their recovered length across references in the locus and multiplying that value by their respective score, thus producing the wscore. Finally wscore is also penalized by the number of frameshifts (if the marker is coding) and number of contigs used in the assembly of the hit. hit_len Number of residues matched in the sample’s contig(s) plus the length of the flanking sequence. cds_len If ref_type is prot this number represents the number of residues corresponding to coding sequence (i.e. exons). If the ref_type is nucl this field shows NA. intron_len If ref_type is prot this number represents the number of residues corresponding to intervening non-coding sequence segments (i.e. introns). If the ref_type is nucl this field shows NA. flanks_len Number of residues included in the flanking sequence. frameshifts Positions of the corrected frameshifts in the output sequence. If the ref_type is nucl this field shows NA. hit_contigs Number of contigs used to assemble the hit. hit_l50 Least number of contigs in the hit that contain 50% of the recovered length. hit_l90 Least number of contigs in the hit that contain 90% of the recovered length. hit_lg50 Least number of contigs in the hit that contain 50% of the reference locus length. hit_lg90 Least number of contigs in the hit that contain 90% of the reference locus length. ctg_names Name of the contigs used in the reconstruction of the hit. Example: NODE_6256_length_619_cov_3.0000_k_169_flag_1;NODE_3991_length_1778_cov_19.0000_k_169_flag_1, for a hit where two contigs were used. ctg_strands Contig strands (+ or -) provided in the same order as ctg_names. Example: +;- indicates that the contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 was matched in the positive strand while the contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 was matched in the ngeative strand. ctg_coords Match coordinates with respect to the contigs in the sample’s assembly. Each segment is expressed as [start]-[end], segments within the same contig are separated by ,, and segments in different contigs are separated by ; which are provided in the same order as ctg_names and ctg_strands. Example: 303-452;694-1626,301-597 indicates that a single segment was matched in contig NODE_6256_length_619_cov_3.0000_k_169_flag_1 in the + strand with coordinates 303-452, while two segments were matched in contig NODE_3991_length_1778_cov_19.0000_k_169_flag_1 in the - strand with coordinates 694-1626 and 301-597 respectively. 27. captus-extract_report.html This is the final Marker Recovery report, summarizing marker extraction statistics across all samples and marker types.\n28. captus-extract.log This is the log from Captus, it contains the command used and all the information shown during the run. If the option --show_less was enabled, the log will also contain all the extra detailed information that was hidden during the run.\n29. clust_id##.##_cov##.##_captus_clusters_refs.fasta This FASTA file contains the cluster representatives that will be searched and extracted across samples (prefix CLR), the loci names are called captus_#. These represent newly discovered homologus markers in contigs that had no hits to other reference proteins or miscellaneous DNA markers. Example \u003eGenusA_speciesA_CAP-captus_1 GACTTGAGCCCCAAAACTAGGTTGGGTGCAGGGGGTCGATCTTGATTTTATTACTCAGGGTGCTTCAGATCAGGTTCTTGCAGCTGAACATGCTTCGGGACATCGACCCTATGGTCAGAATCTTCAATCTGGAAGCTCTGCTGGTGCATCAAGCCAACAAGACATGTCCAAGATCATATGCCAGTAAGAAAACAAGGTATGTAAATACCTCTGCGGGTGGTGCTTTACCTGGAACAGCGTCTGAATCGACTGGCGATATCCCTGCTACTGATGATACCCCCCTGATGGATGCTGCAGGGTAAACAGGTTAATATAGATCTGCTATCTCGAGCCCTGTAACCTGGCTATGCTCTCTTTGCGTCTGCTACTAGATATGCTTCTGGCTTTGCCATTTCTATGAATTCTTATAGAATTTTGATTCAGTCACTATGCAAATTTTATTTGTTATGTTTATAAGGTCTCTTGATTGCGCTCGGGCTCCTGTCTCGGGGGAGCCCTGCGCTCCCTACGCTTACTAGAATATTCATTCTCCCCTATTAAAATAAAAATTTATCGAGATAAAAAAAGAA \u003eGenusA_speciesA_CAP-captus_2 ACCAGATTCCTCCATTGTACAGACAACCATAGGGTCCGACTTTGCAAGACGTTTAAGGCCTTCCACAAGCTTGGGAAGGTCAAATGCCACCTTGCACTGGACAGCCACACGTACCACAGGAGATACAGAAAATTTCATGGCTCGAATTGGATGGGCATCAACTTCCTTCTCGTTTGTTAGAGTGGCATTCTTGGTGATAAATTGGTCCAACCCAACCATGGCAACAGTATTACCACAAGGCACATCCTCCACCGTCTCTTGCCTCTTCCCCATCCAAATAACAGTTCTCTGGACACTCTTCACATACAGGTCTTTCTTCTCTCCAGGAACATAGTTTGGACCCATGATTCTAACTTTCAAACCGGTTGAAACTTTCCCAGAAAAGACTCGACCAAAGGCAAAGAACCTGCCCTTGTCTGATGCAGGAATCATCTTTGAGACATAGAGCATAAGAGGTCCCTCAGGGTCACAATTTCTAATGGCACTAGCATATGCGTCATCTAGTGGACCCTCATACAAATTCTCAACACGAT \u003eGenusB_speciesB_CAP-captus_3 TCCATACATATCAGAATCAGCATCCTTTTTAGGTCTGTATAGGGTTGAAAGAGTGGGCTGAGCAGTAAATAAACCCTTGTCGTATATGTTGTACTGGTCGTCGTTGGCAAATCCAGAGTCCATTCCTTTATCTTGGTTAAATAGCCTCTGGTCATACATAACCTCTCCCTCTCTACCTGCTCCTGTAGAAGCCATGCCAAGTGCAACCTTTTCACTGATATCACGATCTCTGTCTCTTGTGATCTTACTCTTCTTTCCCATTGCAGCATCTTTAGCTTCCAACCTTCTTTCCCTTTCCCTCTCTCGACGTCGTTCTTCACGAATCTTCTCCCTTTGCAACCGCTCTTCCCTTTCCTCCCTTGTCTCCTTTGGTAAATCCTTCTCTTTTTCTCTTACACGCTCAAATTCTCCTTTCTTCTCAGAAGTATCTACTGTGTTTCTATCAGATGGATAAAGAACTGAAGAAGGCGGTGCAGCTCCTGTTCTCTCAGACCGGGCTTTCTGCGCTAATGCTCGGAGCTCCAGCTCCTTCTTCTCCTTCTGCTTCATAAGCATTTCTTTCTGAACCTTGGATCTCATTGCAACTGCTTCTCTTGCTTTCTGTTCTGCAACATACAGAGCTTCAGATAGCTTTGCAAAGTTATCGTTAATTTGAACTTCTTGAAGGCCTCTCCCATCAGCTGCAAGGCGCTTGTCAAGTGGGATCGTATAACCTTTTGGATTCTTCCAATTTGAAATACAAGGAGGAATCTTCCAATCCTGCTGATCCTTCACAGTGACAGGACGGGGAGGGGAATGCATAACAGGCACAGGTGGAGACCCCGAAGCTCTTGGAACACGTTTATGCTTGAACTTTGGAGGCTCAAGTGGATCAACTGGCATCTCCACCATTCTAATTATTCTCTCCTTGGCGCCTGAATTAAATGCAGCTGATTGTTGAGATGGCTTATACTTGATAAA FASTA headers explanation Info All the FASTA files produced by Captus containing extracted markers follow the same header style: Paralogs are ranked according to their wscore which, in turn, is calculated from the percent identity (ident) as well as the percent coverage (cover) with respect to the selected reference sequence (query). The best hit is always ranked 00 and secondary hits start at 01. When a single hit is found for a marker (like in locus 5859 in the image) the ranking 00 is not included in the sequence name, only when multiple hits are found for a marker (like in locus 5865 in the image) the ranking 00 or 01 is included in the sequence name to make them unique. The description field frameshifts is only present when the output sequence has corrected frameshifts and the numbers indicate their position in the output sequence.\nAs you can see, Sample name, Locus name, and Paralog ranking are separated by double underscores (__). This is the reason why we don’t recommend using __ inside your sample names (see sample naming convention)\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Output Files",
    "uri": "/captus.docs/assembly/extract/output/"
  },
  {
    "content": "The next step in the workflow is to perform de novo assembly with MEGAHIT on the cleaned reads. Once the reads have been assembled into contigs, depth of coverage is calculated using Salmon. Captus makes it easy to process many samples in a consistent manner, automatically, and providing a comprehensive Assembly Control HTML report.\nMEGAHIT is an extremely fast and robust de novo assembler that is very memory-efficient thanks to the use of a new data structure called succint De Bruijn Graph (sDBG). Most importantly, accuracy is not sacrificed because it was originally designed for assembling metagenomes. Since then, it has been shown to be an excellent generalist assembler as well.\nIf you are analyzing data with extremely high sequencing depth, or you are trying out parameters and want a quick result, Captus can subsample a fixed number of reads prior to assembly.\nMEGAHIT only provides a quick estimation of contig depth of coverage, therefore we use Salmon to rapidly and accurately calculate the depth of coverage of each contig. Afterwards, contigs with little evidence (by default \u003c1.5x) are automatically filtered.\nIf you assemble your reads in Captus you can also filter the contigs by GC content. For example, remove contigs with \u003e60% GC will remove mostly bacterial contigs. The filtering by GC content and/or by depth of coverage can be repeated multiple times without needing to repeat the assembly and depth of coverage estimation steps.\nCaptus allows you the flexibility to also provide pre-assembled samples. However, we recommend that, whenever you have read data, to assemble it using Captus. For transcriptome assemblies for example, other assemblers will produce lots of redundant contigs (due to isoforms, alleles, etc.) which MEGAHIT tends to collapse into a single contig. This is ideal for phylogenomics (and perhaps also to build non-redundant reference transcriptomes).\nNote In case you assembled your reads elsewhere or you want to use only pre-assembled genomes (e.g., downloaded from GenBank), you can jump ahead to the extract command page.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (18.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Assemble",
    "uri": "/captus.docs/assembly/assemble/"
  },
  {
    "content": "Concept This align module generates several sets of alignments that are ready-to-use in popular phylogenetic tree inference programs (e.g., IQ-TREE, RAxML, ASTRAL). Each alignment set differs from one another in the following four respects: 1) whether they are trimmed, 2) which paralog filter is applied, 3) whether they contain reference sequences, and 4) in which formats . Thus, it is important to understand the differences between each alignment set and carefully evaluate their quality in order to decide which alignment set to use for subsequent analyses.\nOpen the report captus-align_report.html with your browser (internet connection required) to explore and compare general alignment statistics for each locus and each sample! Tips The entire report is based on data stored in the following two files:\ncaptus-align.alignments.tsv captus-align.samples.tsv All tables and plots in the report are interactive powered by Plotly.\nVisit the following sites once to take full advantage of its interactivity:\nhttps://plotly.com/chart-studio-help/getting-to-know-the-plotly-modebar https://plotly.com/chart-studio-help/zoom-pan-hover-controls Contents 1. Stats Comparison at Each Processing Step This plot shows distributions of general alignment statistics at each processing step.\nFeatures:\nSwitch the Marker Type dropdown to change the marker type\n(appeared only when you have more than one marker type). Switch the dropdown on the x-axis to change the variable to show. Click on the legend to toggle hide/show of each format. Description of each processing step Depending on --filter_method argument, you will have up to 12 processing steps as follows:\nProcessing step (Path to alignments) Trimmed Paralog filter With references 02_untrimmed/01_unfiltered_w_refs No None Yes 02_untrimmed/02_naive_w_refs No Naive Yes 02_untrimmed/03_informed_w_refs No Informed Yes 02_untrimmed/01_unfiltered No None No 02_untrimmed/02_naive No Naive No 02_untrimmed/03_informed No Informed No 03_trimmed/01_unfiltered_w_refs Yes None Yes 03_trimmed/02_naive_w_refs Yes Naive Yes 03_trimmed/03_informed_w_refs Yes Informed Yes 03_trimmed/01_unfiltered Yes None No 03_trimmed/02_naive Yes Naive No 03_trimmed/03_informed Yes Informed No For more explanations, read Output Files.\nDescription of each variable Variable Description Unit Sequences Number of sequences in the alignment - Samples Number of samples in the alignment - Sequences Per Sample = Sequences / Samples - Alignment Length Length of the alignment aa/bp Informative Sites Number of parsimony-informative sites that have at least two different characters and at least two of which appear in at least two sequences - Informativeness = (Informative Sites / Alignment Length) * 100 % Uninformative Sites = Alignment Length - Informative Sites\n= Constant Sites + Singleton Sites - Constant Sites Number of invariant sites in the alignment - Singleton Sites Number of variable sites where one character appears in multiple sequences while other characters appear in only one sequence - Patterns Number of unique sites that have different character configurations - Mean Pairwise Identity Mean pairwise sequence identity in the alignment % Missingness Proportion of -, N, X, ?, ., and ~ in the alignment % GC Content GC content of the alignment (inapplicable to AA format) % GC Content at 1st Codon Position GC content at 1st codon position in the alignment\n(only applicable to NT format) % GC Content at 2nd Codon Position GC content at 2nd codon position in the alignment\n(only applicable to NT format) % GC Content at 3rd Codon Position GC content at 3rd codon position in the alignment\n(only applicable to NT format) % For more explanation about sites and patterns, see IQ-TREE’s FAQ: What are the differences between alignment columns/sites and patterns?\n2. Bivariate Relationships and Distributions This plot shows general alignment statistics for each alignment (locus).\nWhen your result contains more than one marker type, the report will include separate plots for each marker type.\nFeatures:\nSwitch the Processing Step dropdown to change the processing step to show the statistics. Switch the dropdowns on the x- and y- axes to change variables to plot on each axis. Click on the legend to toggle hide/show of each format. Description of each processing step Depending on --filter_method argument, you will have up to 12 processing steps as follows:\nProcessing step (Path to alignments) Trimmed Paralog filter With references 02_untrimmed/01_unfiltered_w_refs No None Yes 02_untrimmed/02_naive_w_refs No Naive Yes 02_untrimmed/03_informed_w_refs No Informed Yes 02_untrimmed/01_unfiltered No None No 02_untrimmed/02_naive No Naive No 02_untrimmed/03_informed No Informed No 03_trimmed/01_unfiltered_w_refs Yes None Yes 03_trimmed/02_naive_w_refs Yes Naive Yes 03_trimmed/03_informed_w_refs Yes Informed Yes 03_trimmed/01_unfiltered Yes None No 03_trimmed/02_naive Yes Naive No 03_trimmed/03_informed Yes Informed No For more explanations, read Output Files.\nDescription of each variable Variable Description Unit Sequences Number of sequences in the alignment - Samples Number of samples in the alignment - Sequences Per Sample = Sequences / Samples - Alignment Length Length of the alignment aa/bp Informative Sites Number of parsimony-informative sites that have at least two different characters and at least two of which appear in at least two sequences - Informativeness = (Informative Sites / Alignment Length) * 100 % Uninformative Sites = Alignment Length - Informative Sites\n= Constant Sites + Singleton Sites - Constant Sites Number of invariant sites in the alignment - Singleton Sites Number of variable sites where one character appears in multiple sequences while other characters appear in only one sequence - Patterns Number of unique sites that have different character configurations - Mean Pairwise Identity Mean pairwise sequence identity in the alignment % Missingness Proportion of -, N, X, ?, ., and ~ in the alignment % GC Content GC content of the alignment (inapplicable to AA format) % GC Content at 1st Codon Position GC content at 1st codon position in the alignment\n(only applicable to NT format) % GC Content at 2nd Codon Position GC content at 2nd codon position in the alignment\n(only applicable to NT format) % GC Content at 3rd Codon Position GC content at 3rd codon position in the alignment\n(only applicable to NT format) % For more explanation about sites and patterns, see IQ-TREE’s FAQ: What are the differences between alignment columns/sites and patterns?\n3. Stats Per Sample This plot shows general alignment statistics for each sample.\nWhen your result contains more than one marker type, the report will include separate plots for each marker type.\nFeatures:\nSwitch the Sort Samples by dropdown to re-sort the x-axis by sample name or mean of the variable. Switch the dropdown on the y-axis to change the variable to show. Click on the legend to toggle hide/show of each data series. Description of each variable Variable Description Unit Number of Loci Number of alignments (loci) containing the sample - Mean Ungapped Length Mean sequence length of the sample excluding gaps (-) aa/bp Total Ungapped Length Cumulative sequence length of the sample excluding gaps (-) aa/bp Mean Gaps Mean length of internal gaps (-) - Total Gaps Cumulative length of internal gaps (-) - Mean Ambiguities Mean count of ambiguous characters of the sample - Mean GC Content Mean GC content of the sample (inapplicable to AA format) % Mean GC Content at 1st Codon Position Mean GC content at 1st codon position of the sample (only applicable to NT format) % Mean GC Content at 2nd Codon Position Mean GC content at 2nd codon position of the sample (only applicable to NT format) % Mean GC Content at 3rd Codon Position Mean GC content at 3rd codon position of the sample (only applicable to NT format) % Mean Copies Mean number of sequences per alignment (always 1 for alignments with paralog filter applied) % Created by Gentaro Shigita (11.08.2021)\nLast modified by Gentaro Shigita (17.10.2022)\n",
    "description": "",
    "tags": null,
    "title": "HTML Report",
    "uri": "/captus.docs/assembly/align/report/"
  },
  {
    "content": "Concept No successful marker extractions can be achieved without successful assemblies. Even though this assemble module offers presets tuned for different data types, it is recommendable to repeat this step some times with different parameters to find optimal settings for your own data.\nCaptus assists you in this tedious process by automatically generating a useful report for assembly evaluation.\nJust open captus-assemble_report.html with your browser (internet connection required) to get general assembly statistics across all your samples! Tip The entire report is based on data stored in the following three files:\ncaptus-assemble.assembly_stats.tsv captus-assemble.depth_stats.tsv captus-assemble.length_stats.tsv All tables and plots in the report are interactive powered by Plotly.\nVisit the following sites once to take full advantage of its interactivity:\nhttps://plotly.com/chart-studio-help/getting-to-know-the-plotly-modebar https://plotly.com/chart-studio-help/zoom-pan-hover-controls Contents 1. Summary Table This table shows the general assembly statistics for each sample.\nAll values shown in this table are calculated after filtering by GC content (–max_contig_gc) and/or depth (–min_contig_depth).\nFeatures:\nSwitch the Sort by dropdown to re-sort the table by any column value. Cells are color-coded according to value (high = green; low = pink). Description of each column Column Description Unit Sample Sample name - #Contigs Number of contigs - Total Length Total length of all contigs bp Shortest Contig Shortest contig length bp Longest Contig Longest contig length bp N50 Weighted average of contig lengths that 50% of total assembly length consists of contigs over this length bp L50 Least number of contigs that contain 50% of total assembly length - GC Content Overall GC content % Mean Depth Mean contig depth x 2. Visual Stats In addition to the general statistics shown in the Summary Table, this plot shows more detailed statistics before and after filtering for each sample as a bar graph.\nFeatures:\nSwitch the dropdown at the x-axis to change the variable to show. Click on the legend to toggle hide/show of each data series (only applicable to some variables). Description of each variable Variablea Description Unit #Contigs Number of contigs - Total Length Total length of all contigs bp Shortest Contig Shortest contig length bp Longest Contig Longest contig length bp N50 Weighted average of contig lengths that 50% of total assembly length consists of contigs over this length bp N75 Weighted average of contig lengths that 75% of total assembly length consists of contigs over this length bp L50 Least number of contigs that contain 50% of total assembly length - L75 Least number of contigs that contain 75% of total assembly length - Mean Length Mean contig length bp Median Length Median contig length bp Contig Breakdown by Length Percentage of contigs over 1, 2, 5, 10, 20, and 50 kbp in total number of contigs % Length Breakdown by Contig Length Percentage of contigs over 1, 2, 5, 10, 20, and 50 kbp in total length of contigs % GC Content Overall GC content % Mean Depth Mean contig depth x Median Depth Median contig depth x 3. Length Distribution This plot shows the distribution of contig lengths before and after filtering for each sample as a heatmap.\nFeature:\nSwitch the Variable dropdown at the colorscale to change the variable to show. Description of each variable Variable Description Unit Length Total contig length in the bin bp Fraction (Total contig length in the bin) / (Total assembly length) * 100 % #Contigs Number of contigs in the bin - 4. Depth Distribution This plot shows the distribution of contig depths before and after filtering for each sample as a heatmap.\nFeature:\nSwitch the Variable dropdown at the colorscale to change the variable to show. Description of each variable Variable Description Unit Length Total contig length in the bin bp Fraction (Total contig length in the bin) / (Total assembly length) * 100 % #Contigs Number of contigs in the bin - Created by Gentaro Shigita (11.08.2021)\nLast modified by Gentaro Shigita (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "HTML Report",
    "uri": "/captus.docs/assembly/assemble/report/"
  },
  {
    "content": "Concept Proper cleaning is the first step to perform proper analyses on high-throughput sequencing data. To assess the quality of raw reads and how it is improved by the cleaning, the clean module internally runs the famous quality check program, FastQC, or its faster emulator, Falco, on the reads before and after cleaning. Although both programs generate informative reports, they are in separate files for each sample, each read direction (for paired-end), and before and after cleaning. This makes it tedious to review every report, and can lead to overlook some serious problems, such as residual low-quality bases or adaptor sequences, contamination of different samples, and improper setting of cleaning parameters.\nCaptus summarizes the information in those disparate reports into a single HTML file. All you need to do is open captus-clean_report.html with your browser (internet connection required) to get a quick overview on all your samples, both reads (for paired-end), and before and after cleaning!\nTip The entire report is based on tables stored in the 03_qc_extras directory.\nAll tables and plots in the report are interactive powered by Plotly.\nVisit the following sites once to take full advantage of its interactivity:\nhttps://plotly.com/chart-studio-help/getting-to-know-the-plotly-modebar https://plotly.com/chart-studio-help/zoom-pan-hover-controls Contents The report comprises the following nine sections:\nConcept Contents 1. Summary Table 2. Stats on Reads/Bases 3. Per Base Quality 4. Per Read Quality 5. Read Length Distribution 6. Per Base Nucleotide Content 7. Per Read GC Content 8. Sequence Duplication Level 9. Adaptor Content A brief description and interactive example of each section is given below.\nBy switching the tabs at the top of each plot, you can compare the plot produced by Captus with the corresponding plot from FastQC.\n1. Summary Table This table shows general cleaning statistics for each sample.\nFeatures:\nSwitch the Sort by dropdown to re-sort the table by any column value. Cells are color-coded according to value (high = green; low = pink). Captus FastQC Description of each column Column Description Unit Sample Sample name - Input Reads Number of reads before cleaning - Input Bases Number of bases before cleaning bp Output Reads Number of reads passed cleaning - Output Reads% = (Output Reads / Input Reads) * 100 % Output Bases Number of bases passed cleaning bp Output Bases% = (Output Bases / Input Bases) * 100 % Mean Read Length% = (Mean read length after cleaning / Mean read length before cleaning) * 100 % ≥Q20 Reads% Percentage of reads with mean Phred quality score over 20 after cleaning % ≥Q30 Reads% Percentage of reads with mean Phred quality score over 30 after cleaning % GC% Mean GC content in the reads after cleaning % Adapter% Percentage of reads containing adaptor sequences before cleaning % 2. Stats on Reads/Bases Captus cleans reads through two consecutive rounds of adaptor trimming (Round1, Round2) followed by quality trimming and filtering.\nThis plot shows changes in the number of reads (left panel) and bases (right panel) at each step of the cleaning process.\nFeatures:\nSwitch the buttons at the top to choose whether to show counts or percentages. Samples are sorted by the number or percentage of bases passed cleaning. Click on the legend to toggle hide/show of each data series. Captus FastQC There is no corresponding plot.\n3. Per Base Quality This plot shows the range of Phred quality score at each position in the reads before and after cleaning.\nFor more details, read FastQC documentation.\nFeature:\nSwitch the dropdown at the top to change the variable to show, these variables represent the elements of the boxplots in the FastQC report. Captus FastQC 4. Per Read Quality This plot shows the distribution of mean Phred quality score for each read before and after cleaning.\nFor more details, read FastQC documentation. Captus FastQC 5. Read Length Distribution This plot shows the distribution of read lengths before and after cleaning.\nFor more details, read FastQC documentation. Captus FastQC 6. Per Base Nucleotide Content This plot shows the composition of each nucleotide (A, T, G, C) at each position in the reads before and after cleaning.\nIf a particular nucleotide is overrepresented at a certain position in the reads, you will see the color corresponding to that nucleotide; otherwise, the plot will be a uniform grayish color.\nFor more details, read FastQC documentation. Captus FastQC 7. Per Read GC Content This plot shows the frequency of GC content in the reads before and after cleaning.\nBroader or bimodal peaks may indicate contamination with DNA from different organisms.\nFor more details, read FastQC documentation. Captus FastQC 8. Sequence Duplication Level This plot shows the percentage of sequences with different degrees of duplication before and after cleaning.\nFor more details, read FastQC documentation.\nFeature:\nClick on the legend to toggle hide/show of each data series. Captus FastQC 9. Adaptor Content This plot shows the cumulative adaptor content at each position in the reads before and after cleaning.\nFor more details, read FastQC documentation. Captus FastQC Created by Gentaro Shigita (11.08.2021)\nLast modified by Gentaro Shigita (23.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "HTML Report",
    "uri": "/captus.docs/assembly/clean/report/"
  },
  {
    "content": "Concept The output from this extract module, such as how many loci are recovered, in how many samples, and to what extent, would be the most direct indication of whether your analysis is successful or not, and thus would be of most interest to many users. However, collecting, summarizing, and visualizing such important information can be backbreaking, especially in a phylo\"genomic\" project which typically employs hundreds or even thousands of samples and loci.\nDon’t worry, Captus automatically generates an informative report! Open captus-extract_report.html with your browser (internet connection required) to explore your extraction result at various scales, from the global level to the single sample or single locus level. Tip The entire report is based on data stored in captus-extract_stats.tsv.\nAll tables and plots in the report are interactive powered by Plotly.\nVisit the following sites once to take full advantage of its interactivity:\nhttps://plotly.com/chart-studio-help/getting-to-know-the-plotly-modebar https://plotly.com/chart-studio-help/zoom-pan-hover-controls Example Here is a small example of the report you can play with!\nThe heatmap shows a extraction result of the Angiosperms353 (Johnson et al., 2019) loci from targeted-capture data of four plant species. The blue bars along with x- and y-axes indicate how many loci are recovered in each sample and how many samples each locus is recovered in, respectively.\nNote When your result contains more than one marker type, the report will include separate plots for each marker type. For loci with more than one copy found in a sample, information on best hit (hit with the highest weighted score) will be shown. Information on loci with no samples recovered and samples with no loci recovered will not be shown. Features 1. Hover information Hover mouse cursor over the heatmap to see detailed information about each single data point.\nList of the information to be shown Field Description Unit Sample Sample name - Marker type Marker type (NUC = Nuclear proteins; PTD = Plastidial proteins; MIT = Mitochondrial proteins; DNA = Miscellaneous DNA markers; CLR = Cluster-derived DNA markers) - Locus Locus name - Ref name Reference sequence name selected - Ref coords Matched coordinates with respect to the reference sequence (Consecutive coordinates separated by , indicate partial hits on the same contig; coordinates separated by ; indicate hits on different contigs) - Ref type Reference sequence format (nucl = nucleotides; prot = amino acids) - Ref len matched Total length of Ref coords aa/bp Total hits (copies) Number of hits found (Values greater than 1 imply the presence of paralogs) - Recovered length Percentage of reference sequence length recovered, calcurated as (Ref len matched / Reference sequence length) * 100 % Identity Sequence identity of the recovered sequence to the reference sequence % Score Score inspired by Scipio, calculated as (matches - mismatches) / reference sequence length - Weighted score Weighted score to address multiple reference sequences per locus\n(for details, read Information included in the table) - Hit length Length of sequence recovered bp CDS length Total length of coding sequences (CDS) recovered (always NA when the ref_type is nucl) bp Intron length Total length of introns recovered (always NA when the ref_type is nucl) bp Flanking length Total length of flanking sequences recovered bp Number of frameshifts Number of corrected frameshifts in the extracted sequence\n(always 0 when ref_type is nucl) - Position of frameshifts Positions of corrected frameshifts in the extracted sequence\n(NA when no frameshift is detected or ref_type is nucl) - Contigs in best hit Number of contigs used to assemble the best hit - Best hit L50 Least number of contigs in best hit that contain 50% of the best hit’s recovered length - Best hit L90 Least number of contigs in best hit that contain 90% of the best hit’s recovered length - Best hit LG50 Least number of contigs in best hit that contain 50% of the reference locus length - Best hit LG90 Least number of contigs in best hit that contain 90% of the reference locus length - * When your data is huge (number of samples * number of loci \u003e 500k), only Sample, Locus, and the variable selected in the Variable dropdown will be shown.\n2. Variable dropdown Switch this dropdown to change the variable to be shown as a heatmap among the following options:\nVariable Description Unit Recovered Length Percentage of reference sequence length recovered % Identity Sequence identity of the recovered sequence to the reference sequence % Total Hits (Copies) Number of hits found (Values greater than 1 imply the presence of paralogs) - Score Score inspired by Scipio, calculated as (matches - mismatches) / reference sequence length - Weighted Score Weighted score to address multiple reference sequences per locus\n(for details, read Information included in the table) - Number of Frameshifts Number of corrected frameshifts in the extracted sequence\n(always 0 if the reference sequence is in nucleotide) - Contigs in Best Hit Number of contigs used to assemble the best hit - Best Hit L50 Least number of contigs in best hit that contain 50% of the best hit’s recovered length - Best Hit L90 Least number of contigs in best hit that contain 90% of the best hit’s recovered length - Best Hit LG50 Least number of contigs in best hit that contain 50% of the reference locus length - Best Hit LG90 Least number of contigs in best hit that contain 90% of the reference locus length - 3. Sort by Value dropdown Switch this dropdown to change the sorting manner of each axis as follow:\nLabel Locus (x-axis) Sample (y-axis) None Sort by name Sort by name Mean X Sort by mean value Sort by name Mean Y Sort by name Sort by mean value Mean Both Sort by mean value Sort by mean value Total X Sort by total value Sort by name Total Y Sort by name Sort by total value Total Both Sort by total value Sort by total value Created by Gentaro Shigita (11.08.2021)\nLast modified by Gentaro Shigita (16.09.2022)\n",
    "description": "",
    "tags": null,
    "title": "HTML Report",
    "uri": "/captus.docs/assembly/extract/report/"
  },
  {
    "content": "Using conda/mamba (recommended) Captus is available as a conda package. If you have conda or mamba installed, you can easily create a new environment and install Captus with all dependencies using the following command:\nconda create -n captus -c bioconda -c conda-forge captus Important for macOS users One of the builds of the latest version of MEGAHIT (v1.2.9) on Bioconda is broken. To ensure you install a functional one, please specify the build number as follows:\nconda create -n captus -c bioconda -c conda-forge captus megahit=1.2.9=hfbae3c0_0 Check that Captus was correctly installed:\nconda activate captus captus -h If the program was correctly installed, you will see the following help message:\nusage: captus command [options] Captus 1.1.0: Assembly of Phylogenomic Datasets from High-Throughput Sequencing data Captus-assembly commands: command Program commands (in typical order of execution) clean = Trim adaptors and quality filter reads with BBTools, run FastQC on the raw and cleaned reads assemble = Perform de novo assembly with MEGAHIT and estimate contig depth of coverage with Salmon: Assembling reads that were cleaned with the 'clean' command is recommended, but reads cleaned elsewhere are also allowed extract = Recover targeted markers with BLAT and Scipio: Extracting markers from the assembly obtained with the 'assemble' command is recommended, but any other assemblies in FASTA format are also allowed align = Align extracted markers across samples with MAFFT or MUSCLE: Marker alignment depends on the directory structure created by the 'extract' command. This step also performs paralog filtering and alignment trimming using ClipKIT Help: -h, --help Show this help message and exit --version Show Captus' version number For help on a particular command: captus_assembly command -h Manual installation If you are unable to use conda/mamba for any reason, you will need to manually install all the dependencies listed below:\nDependency Version URL Python \u003e=3.6 https://www.python.org BBTools https://jgi.doe.gov/data-and-tools/bbtools BioPerl https://bioperl.org ClipKIT \u003e=1.3.0 https://github.com/JLSteenwyk/ClipKIT Falco \u003e=0.3.0 https://github.com/smithlabcode/falco FastQC https://www.bioinformatics.babraham.ac.uk/projects/fastqc MAFFT https://mafft.cbrc.jp/alignment/software MEGAHIT 1.2.9 https://github.com/voutcn/megahit MMseqs2 https://github.com/soedinglab/MMseqs2 MUSCLE \u003e=5.1 https://www.drive5.com/muscle pandas \u003e=2.1.0 https://pandas.pydata.org Plotly https://github.com/plotly/plotly.py pigz https://zlib.net/pigz Salmon \u003e=1.10.0 https://github.com/COMBINE-lab/salmon tqdm https://github.com/tqdm/tqdm VSEARCH https://github.com/torognes/vsearch YAML https://metacpan.org/pod/YAML * The following two dependencies are bundled with Captus, so no additional installation is required.\nDependency Version URL BLAT 37x1 http://hgdownload.soe.ucsc.edu/admin/exe Scipio 1.4.1 https://www.webscipio.org Once you have all the dependencies installed, you can proceed to clone the repository and install Captus as follows:\ngit clone https://github.com/edgardomortiz/Captus.git cd Captus pip install . captus -h Alternatively, you can run Captus using the wrapper script captus_assembly-runner.py as follows:\ngit clone https://github.com/edgardomortiz/Captus.git ./Captus/captus_assembly-runner.py -h Created by Edgardo M. Ortiz (06.08.2021)\nLast modified by Gentaro Shigita (19.12.2024)\n",
    "description": "",
    "tags": null,
    "title": "Installation",
    "uri": "/captus.docs/basics/installation/"
  },
  {
    "content": "The next step in the workflow is to search markers within the assemblies and extract them. For that you need to provide Captus reference sequence(s) of the marker(s) you want to extract. You can provide coding sequences in either nucleotide or aminoacid, in this case, protein extraction will be performed with Scipio. One key advantage of Scipio is its ability of reconstructing gene models (i.e., exons + introns) from separate contigs in highly fragmented assemblies, which are not uncommon when analyzing hybridization capture or genome skimming data.\nIf you want to extract any other DNA marker (entire genes with introns, ribosomal genes, non-coding regions, RAD reference loci, etc.) you provide your reference(s) in nucleotide format, in this case the extraction is performed using BLAT and our own code to stitch and extract partial hits if necessary in an analogous fashion to Scipio’s method.\n",
    "description": "",
    "tags": null,
    "title": "Extract",
    "uri": "/captus.docs/assembly/extract/"
  },
  {
    "content": "(and other common options) Throughout Captus’ modules we provide common options that allow you limit the computer’s resources available to Captus, change the way of running parallel tasks, and control the amount of text shown during a run:\n--ram With this option you can specify the maximum RAM in GB that Captus is allowed to use. For example, if your system has 64 GB of RAM and you want to limit the use to 32.5 GB you would set the argument --ram 32.5.\nThis argument is optional, the default is auto (= 99% of available RAM).\n--threads Similarly, you can specify the maximum number of CPU cores that Captus is allowed to use. If your system has 16 CPU cores but you need some cores for other analyses you could reduce it to, for example, 8 cores with --threads 8.\nThis argument is optional, the default is auto (= all CPU cores).\n--concurrent This option sets the maximum number of tasks to run in parallel at any moment. For example, let’s imagine you set --threads 16 and --concurrent 2, this means that Captus will run only 2 tasks in parallel but each of those tasks can use up to 8 CPU cores.\nThis argument is optional, the default is auto (the automatic adjustment varies between analysis steps).\n--debug This flag enables the debugging mode, this disables parallelization so errors can be logged to screen. If you are seeing some samples failing steps or some other unexpected behavior you can enable --debug and submit the error shown to the Issues (https://github.com/edgardomortiz/Captus/issues) section in our GitHub repository.\n--show_less This flag produces less verbose screen printout. Essentially, information about each sample will not be shown (but still logged) during the run.\nCreated by Edgardo M. Ortiz (06.08.2021)\nLast modified by Edgardo M. Ortiz (11.11.2022)\n",
    "description": "",
    "tags": null,
    "title": "Parallelization",
    "uri": "/captus.docs/basics/parallelization/"
  },
  {
    "content": "The last step in the Captus workflow is to align the extracted markers so you can estimate phylogenetic trees with your favorite tool (e.g., IQ-TREE, RAxML, MrBayes, SVDQuartets, etc.).\nCaptus starts this step by gathering all the markers across your extracted samples and building a FASTA file per marker. Then, it will add the references used during extraction, these are useful to improve alignment since they serve as guides. Then Captus aligns the files using MAFFT or MUSCLE, however, if you choose to align coding sequence in aminoacid (AA) and nucleotide (NT) in the same run, Captus will first align the AA version with MAFFT or MUSCLE and then use that alignment as template to align the NT version, thus producing an codon-aware alignment of the coding sequence in nucleotides. Once alignment is completed, paralogs are filtered. Finally, gappy columns are removed with ClipKIT (but you can any other ClipKIT’s filtering strategy) as well as exceptionally short sequences which tend to decrease phylogenetic accuracy.\nAt the end, Captus provides several alignment formats from which you can choose the most appropriate for your needs as well as a comprehensive HTML report summarizing alignment statistics along the multiple stages of the align step.\n",
    "description": "",
    "tags": null,
    "title": "Align",
    "uri": "/captus.docs/assembly/align/"
  },
  {
    "content": "Captus Assembly of phylogenomic datasets from High-Throughput Sequencing data ",
    "description": "",
    "tags": null,
    "title": "Captus",
    "uri": "/captus.docs/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/captus.docs/categories/"
  },
  {
    "content": "Edgardo M. Ortiz Code and documentation.\nGentaro Shigita Documentation and coding of HTML reports.\nAny questions and feature requests are welcome!\n",
    "description": "",
    "tags": null,
    "title": "Credits",
    "uri": "/captus.docs/more/credits/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/captus.docs/tags/"
  }
]
